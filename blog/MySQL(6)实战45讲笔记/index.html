<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>MySQL(6)实战45讲笔记 | HahHome</title><meta name="author" content="spongehah"><meta name="copyright" content="spongehah"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="主要参考：MySQL实战45讲 次要参考：xiaolingcoding图解MySQL  01 讲基础架构：一条SQL查询语句是如何执行的   第一步：连接器连接sleep1show processlist  连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在show processlist命令中看到它。文本中这个图是show processlist的结果，其中的Command列显"><meta property="og:type" content="article"><meta property="og:title" content="MySQL(6)实战45讲笔记"><meta property="og:url" content="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/index.html"><meta property="og:site_name" content="HahHome"><meta property="og:description" content="主要参考：MySQL实战45讲 次要参考：xiaolingcoding图解MySQL  01 讲基础架构：一条SQL查询语句是如何执行的   第一步：连接器连接sleep1show processlist  连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在show processlist命令中看到它。文本中这个图是show processlist的结果，其中的Command列显"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://blog.hahhome.top/img/cover_default_img/02.webp"><meta property="article:published_time" content="2023-10-01T06:50:06.000Z"><meta property="article:modified_time" content="2023-10-01T06:36:03.052Z"><meta property="article:author" content="spongehah"><meta property="article:tag" content="MySQL"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://blog.hahhome.top/img/cover_default_img/02.webp"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="canonical" href="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="/pluginsSrc/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="/pluginsSrc/node-snackbar/dist/snackbar.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="/pluginsSrc/@fancyapps/ui/dist/fancybox/fancybox.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: true
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":100,"languages":{"author":"作者: spongehah","link":"链接: ","source":"来源: HahHome","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: '/pluginsSrc/flickr-justified-gallery/dist/fjGallery.min.js',
      css: '/pluginsSrc/flickr-justified-gallery/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: true,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"MySQL(6)实战45讲笔记",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2023-10-01 14:36:03"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/universe.css"><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="/css/mouse.css"><link rel="stylesheet" href="https://npm.elemecdn.com/ethan4116-blog/lib/css/plane_v2.css"><link rel="stylesheet" href="/css/cat.css"><link rel="stylesheet" href="/css/rightMenu.css"><link rel="stylesheet" href="/css/iconfont.css"><div id="myscoll"></div><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css"><meta name="generator" content="Hexo 6.3.0"></head><body><script>window.paceOptions = {
  restartOnPushState: false
}

document.addEventListener('pjax:send', () => {
  Pace.restart()
})</script><link rel="stylesheet" href="/css/loading-bar.css"><script src="/pluginsSrc/pace-js/pace.min.js"></script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.webp" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-book"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/songs/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fas fa-gamepad"></i><span> 游戏</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书单</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fas fa-comments"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/img/cover_default_img/02.webp)"><nav id="nav"><span id="blog-info"><a href="/" title="HahHome"><span class="site-name">HahHome</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-book"></i><span> 文章</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/songs/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/games/"><i class="fa-fw fas fa-gamepad"></i><span> 游戏</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li><li><a class="site-page child" href="/books/"><i class="fa-fw fas fa-book"></i><span> 书单</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fas fa-comments"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">MySQL(6)实战45讲笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-01T06:50:06.000Z" title="发表于 2023-10-01 14:50:06">2023-10-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-10-01T06:36:03.052Z" title="更新于 2023-10-01 14:36:03">2023-10-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">47.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>148分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="MySQL(6)实战45讲笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>主要参考：MySQL实战45讲</p><p>次要参考：xiaolingcoding图解MySQL</p></blockquote><h1 id="01-讲基础架构：一条SQL查询语句是如何执行的"><a href="#01-讲基础架构：一条SQL查询语句是如何执行的" class="headerlink" title="01 讲基础架构：一条SQL查询语句是如何执行的"></a>01 讲基础架构：一条SQL查询语句是如何执行的</h1><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/0d2070e8f84c4801adbfa03bda1f98d9.png" alt="img"></p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/mysql%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B.png" alt="查询语句执行流程"></p><h2 id="第一步：连接器"><a href="#第一步：连接器" class="headerlink" title="第一步：连接器"></a>第一步：连接器</h2><h3 id="连接sleep"><a href="#连接sleep" class="headerlink" title="连接sleep"></a>连接sleep</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show processlist</span><br></pre></td></tr></table></figure><p>连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在show processlist命令中看到它。文本中这个图是show processlist的结果，其中的Command列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/f2da4aa3a672d48ec05df97b9f992fed.png" alt="img"></p><p>客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数<strong>wait_timeout</strong>控制的，默认值是<strong>8小时</strong>。</p><p>如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。</p><p>MySQL 服务支持的最大连接数由 <strong>max_connections</strong> 参数控制，比如我的 MySQL 服务默认是 <strong>151</strong> 个,超过这个值，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”。</p><h3 id="长连接"><a href="#长连接" class="headerlink" title="长连接"></a>长连接</h3><p>数据库里面，<strong>长连接</strong>是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。</p><p>建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是<strong>尽量使用长连接</strong>。</p><p><strong>但是全部使用长连接</strong>后，你可能会发现，有些时候MySQL占用<strong>内存涨得特别快</strong>，这是因为MySQL在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。</p><p>怎么<strong>解决</strong>这个问题呢？你可以考虑以下两种方案。</p><ol><li><code>定期断开长连接</code>。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li><li>如果你用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行 <code>mysql_reset_connection来重新初始化连接资源</code>。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li></ol><h2 id="第二步：查询缓存"><a href="#第二步：查询缓存" class="headerlink" title="第二步：查询缓存"></a>第二步：查询缓存</h2><p><strong>大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。</strong></p><p><strong>查询缓存的命中率会非常低</strong>，并且<strong>在一个表上有更新的时候，跟这个表有关的查询缓存会失效</strong>。</p><p>除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。</p><p>可以将参数query_cache_type设置成DEMAND，这样对于默认的SQL语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用SQL_CACHE显式指定，像下面这个语句一样：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select SQL_CACHE * from T where ID=10；</span><br></pre></td></tr></table></figure><p>需要注意的是，MySQL 8.0版本直接将查询缓存的整块功能删掉了，也就是说<strong>8.0开始彻底没有这个功能</strong>了。</p><h2 id="第三步：分析器"><a href="#第三步：分析器" class="headerlink" title="第三步：分析器"></a>第三步：分析器</h2><p>MySQL需要知道你要做什么，因此需要对SQL语句做解析。</p><p>分析器先会做“<strong>词法分析</strong>”。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。</p><ul><li>MySQL从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名T”，把字符串“ID”识别成“列ID”。</li></ul><p>做完了这些识别以后，就要做“<strong>语法分析</strong>”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。</p><ul><li><p>如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句select少打了开头的字母“s”。</p></li><li><p>一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。</p></li></ul><h2 id="第四步：优化器"><a href="#第四步：优化器" class="headerlink" title="第四步：优化器"></a>第四步：优化器</h2><p>优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的join：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t1 join t2 using(ID)  where t1.c=10 and t2.d=20;</span><br></pre></td></tr></table></figure><ul><li>既可以先从表t1里面取出c&#x3D;10的记录的ID值，再根据ID值关联到表t2，再判断t2里面d的值是否等于20。</li><li>也可以先从表t2里面取出d&#x3D;20的记录的ID值，再根据ID值关联到t1，再判断t1里面c的值是否等于10。</li></ul><p>这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。</p><p>优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等，没关系，我会在后面的文章中单独展开说明优化器的内容。</p><h2 id="第五步：执行器"><a href="#第五步：执行器" class="headerlink" title="第五步：执行器"></a>第五步：执行器</h2><p>MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。</p><p>开始执行的时候，要先判断一下你对这个表T有没有执行查询的<strong>权限</strong>，如果没有，就会返回没有权限的错误，如下所示(在工程实现上，如果命中查询缓存，会在查询缓存放回结果的时候，做权限验证。查询也会在优化器之前调用precheck验证权限)。</p><p>如果<strong>有权限</strong>，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</p><p><strong>eg：</strong></p><p>比如我们这个例子中的表T中，ID字段没有索引，那么执行器的执行流程是这样的：</p><ol><li>调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；</li><li>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</li><li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</li></ol><p>至此，这个语句就执行完成了。</p><p>对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。</p><p>你会在数据库的慢查询日志中看到一个<strong>rows_examined</strong>的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。</p><p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此<strong>引擎扫描行数跟rows_examined并不是完全相同的。</strong>我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。</p><h1 id="02-讲日志系统：一条SQL更新语句是如何执行的"><a href="#02-讲日志系统：一条SQL更新语句是如何执行的" class="headerlink" title="02 讲日志系统：一条SQL更新语句是如何执行的"></a>02 讲日志系统：一条SQL更新语句是如何执行的</h1><h2 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h2><p>MySQL里经常说到的WAL技术，WAL的全称是Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。</p><p>具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事。</p><p>如果今天赊账的不多，掌柜可以等打烊后再整理。但如果某天赊账的特别多，粉板写满了，又怎么办呢？这个时候掌柜只好放下手中的活儿，把粉板中的一部分赊账记录更新到账本中，然后把这些记录从粉板上擦掉，为记新账腾出空间。</p><p>与此类似，InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么这块“粉板”总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示:</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230919205345326.png" alt="image-20230919205345326"></p><p>write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。</p><p>write pos和checkpoint之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果write pos追上checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把checkpoint推进一下。</p><blockquote><p>有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为<strong>crash-safe</strong>。</p></blockquote><h2 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h2><p>前面我们讲过，MySQL整体来看，其实就有两块：一块是Server层，它主要做的是MySQL功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板<strong>redo log是InnoDB引擎特有的日志</strong>，而<strong>Server层也有自己的日志，称为binlog</strong>（归档日志）。</p><p>我想你肯定会问，为什么会有两份日志呢？</p><p>因为最开始MySQL里并没有InnoDB引擎。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统——也就是redo log来实现crash-safe能力。</p><p>这两种日志有以下三点不同。</p><ol><li><code>redo log是InnoDB引擎特有的</code>；<code>binlog是MySQL的Server层实现的</code>，所有引擎都可以使用。</li><li>redo log是<strong>物理日志</strong>，记录的是“在某个数据页上做了什么修改”；binlog是<strong>逻辑日志</strong>，记录的是这个语句的原始逻辑，比如“给ID&#x3D;2这一行的c字段加1 ”（三种格式）。</li><li>redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li></ol><h2 id="更新语句执行过程"><a href="#更新语句执行过程" class="headerlink" title="更新语句执行过程"></a>更新语句执行过程</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update T set c=c+1 where ID=2;</span><br></pre></td></tr></table></figure><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png" alt="img"></p><p>你可能注意到了，最后三步看上去有点“绕”，将redo log的写入拆成了两个步骤：prepare和commit，这就是”两阶段提交”。</p><h2 id="redo-log的两阶段提交"><a href="#redo-log的两阶段提交" class="headerlink" title="redo log的两阶段提交"></a>redo log的两阶段提交</h2><p>由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。</p><p>仍然用前面的update语句来做例子。假设当前ID&#x3D;2的行，字段c的值是0，再假设执行update语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？</p><ol><li><strong>先写redo log后写binlog</strong>。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。<br>但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。<br>然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。</li><li><strong>先写binlog后写redo log</strong>。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。</li></ol><p>可以看到，<strong>如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致</strong>。</p><p>简单说，redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。</p><p>即<strong>保证主库和从库的数据一致性</strong></p><blockquote><p>redo log用于保证crash-safe能力。<strong>innodb_flush_log_at_trx_commit</strong>这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失。</p><p><strong>sync_binlog</strong>这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。</p></blockquote><h1 id="03-讲事务隔离：为什么你改了我还看不见"><a href="#03-讲事务隔离：为什么你改了我还看不见" class="headerlink" title="03 讲事务隔离：为什么你改了我还看不见"></a>03 讲事务隔离：为什么你改了我还看不见</h1><p>提到事务，你肯定会想到ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性），今天我们就来说说其中I，也就是“隔离性”。</p><p>当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。</p><p>在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。下面我逐一为你解释：</p><ul><li>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。</li><li>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。</li><li>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。</li><li>串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。</li></ul><p><strong>总结：</strong></p><p>1、务的特性：原子性、一致性、隔离性、持久性<br>2、多事务同时执行的时候，可能会出现的问题：脏读、不可重复读、幻读<br>3、事务隔离级别：读未提交、读提交、可重复读、串行化<br>4、不同事务隔离级别的区别：<br>读未提交：一个事务还未提交，它所做的变更就可以被别的事务看到<br>读提交：一个事务提交之后，它所做的变更才可以被别的事务看到<br>可重复读：一个事务执行过程中看到的数据是一致的。未提交的更改对其他事务是不可见的<br>串行化：对应一个记录会加读写锁，出现冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行</p><p>5、配置方法：启动参数transaction-isolation<br>6、事务隔离的实现：每条记录在更新的时候都会同时记录一条回滚操作。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（MVCC）。</p><p>7、回滚日志什么时候删除？系统会判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除。<br>8、什么时候不需要了？当系统里么有比这个回滚日志更早的read-view的时候。</p><p>9、为什么<strong>尽量不要使用长事务</strong>。长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。</p><p>10、事务启动方式：一、显式启动事务语句，begin或者start transaction,提交commit，回滚rollback；二、set autocommit&#x3D;0，该命令会把这个线程的自动提交关掉。这样只要执行一个select语句，事务就启动，并不会自动提交，直到主动执行commit或rollback或断开连接。<br>11、建议使用方法一，如果考虑多一次交互问题，可以使用commit work and chain语法。在autocommit&#x3D;1的情况下用begin显式启动事务，如果执行commit则提交事务。如果执行commit work and chain则提交事务并自动启动下一个事务。</p><p>可以在information_schema库的innodb_trx这个表中<strong>查询长事务</strong>，比如下面这个语句，用于查找持续时间超过60s的事务。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60</span><br></pre></td></tr></table></figure><h1 id="04-讲深入浅出索引-上"><a href="#04-讲深入浅出索引-上" class="headerlink" title="04 讲深入浅出索引(上)"></a>04 讲深入浅出索引(上)</h1><p><strong>一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。</strong></p><h2 id="Hash索引"><a href="#Hash索引" class="headerlink" title="Hash索引"></a>Hash索引</h2><p>哈希表是一种以键-值（key-value）存储数据的结构，我们只要输入待查找的值即key，就可以找到其对应的值即Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。</p><p>不可避免地，多个key值经过哈希函数的换算，会出现同一个值的情况。处理这种情况的一种方法是，拉出一个链表。</p><p>假设，你现在维护着一个身份证信息和姓名的表，需要根据身份证号查找对应的名字，这时对应的哈希索引的示意图如下所示：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/0c62b601afda86fe5d0fe57346ace957.png" alt="img"></p><p>需要注意的是，图中四个ID_card_n的值并不是递增的，这样做的好处是增加新的User时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以<strong>哈希索引做区间查询(范围查询)的速度是很慢的</strong>。</p><p>你可以设想下，如果你现在要找身份证号在[ID_card_X, ID_card_Y]这个区间的所有用户，就必须全部扫描一遍了。</p><p>所以，<strong>哈希表这种结构适用于只有等值查询的场景</strong>，比如Memcached及其他一些NoSQL引擎。</p><h2 id="有序数组"><a href="#有序数组" class="headerlink" title="有序数组"></a>有序数组</h2><p>而<strong>有序数组在等值查询和范围查询场景中的性能就都非常优秀</strong>。还是上面这个根据身份证号查名字的例子，如果我们使用有序数组来实现的话，示意图如下所示：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230920194507068.png" alt="image-20230920194507068"></p><p>这时候如果你要查ID_card_n2对应的名字，用二分法就可以快速得到，这个**时间复杂度是O(log(N))**。</p><p>这个索引结构<strong>支持范围查询</strong>。你要查身份证号在[ID_card_X, ID_card_Y]区间的User，可以先用二分法找到ID_card_X（如果不存在ID_card_X，就找到大于ID_card_X的第一个User），然后向右遍历，直到查到第一个大于ID_card_Y的身份证号，退出循环。</p><p>如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要<strong>更新数据</strong>的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，<strong>成本太高</strong>。</p><p>所以，<strong>有序数组索引只适用于静态存储引擎</strong>，比如你要保存的是2017年某个城市的所有人口信息，这类不会再修改的数据。</p><h2 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h2><p>二叉搜索树也是课本里的经典数据结构了。还是上面根据身份证号查名字的例子，如果我们用二叉搜索树来实现的话，示意图如下所示：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/04fb9d24065635a6a637c25ba9ddde68.png" alt="img"></p><p>二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查ID_card_n2的话，按照图中的搜索顺序就是按照UserA -&gt; UserC -&gt; UserF -&gt; User2这个路径得到。这个**时间复杂度是O(log(N))**。</p><p>当然为了维持O(log(N))的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是O(log(N))。</p><p>你可以想象一下一棵100万节点的平衡二叉树，树高20。一次查询可能需要访问20个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要10 ms左右的寻址时间。也就是说，对于一个100万行的表，如果使用二叉树来存储，单独访问一个行可能需要20个10 ms的时间，<strong>这个查询可真够慢的</strong>。</p><p>为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。这里，“N叉”树中的“N”取决于数据块的大小。</p><p><strong>N叉树</strong>由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。</p><h2 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230920195036279.png" alt="image-20230920195036279"></p><p>从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。</p><p>主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。</p><p>非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。</p><p>根据上面的索引结构说明，我们来讨论一个问题：<strong>基于主键索引和普通索引的查询有什么区别？</strong></p><ul><li>如果语句是select * from T where ID&#x3D;500，即主键查询方式，则只需要搜索ID这棵B+树；</li><li>如果语句是select * from T where k&#x3D;5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。</li></ul><p>也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，<strong>我们在应用中应该尽量使用主键查询</strong>。</p><p>当不使用有序索引时，插入可能造成<strong>页分裂</strong>，严重影响数据库性能</p><p><strong>显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。</strong></p><p><strong>总结：</strong></p><p>1.索引的作用：提高数据查询效率<br>2.常见索引模型：哈希表、有序数组、搜索树</p><p>3.哈希表：键 - 值(key - value)。<br>4.哈希思路：把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置<br>5.哈希冲突的处理办法：链表<br>6.哈希表适用场景：只有等值查询的场景</p><p>7.有序数组：按顺序存储。查询用二分法就可以快速查询，时间复杂度是：O(log(N))<br>8.有序数组查询效率高，更新效率低<br>9.有序数组的适用场景：静态存储引擎。</p><p>10.二叉搜索树：每个节点的左儿子小于父节点，父节点又小于右儿子<br>11.二叉搜索树：查询时间复杂度O(log(N))，更新时间复杂度O(log(N))<br>12.数据库存储大多不适用二叉树，因为树高过高，会适用N叉树</p><p>13.InnoDB中的索引模型：B+Tree<br>14.索引类型：主键索引、非主键索引<br>主键索引的叶子节点存的是整行的数据(聚簇索引)，非主键索引的叶子节点内容是主键的值(二级索引)<br>15.主键索引和普通索引的区别：主键索引只要搜索ID这个B+Tree即可拿到数据。普通索引先搜索索引拿到主键值，再到主键索引树搜索一次(回表)</p><p>16.一个数据页满了，按照B+Tree算法，新增加一个数据页，叫做页分裂，会导致性能下降。空间利用率降低大概50%。当相邻的两个数据页利用率很低的时候会做数据页合并，合并的过程是分裂过程的逆过程。<br>17.从性能和存储空间方面考量，自增主键往往是更合理的选择</p><h1 id="05-讲深入浅出索引-下"><a href="#05-讲深入浅出索引-下" class="headerlink" title="05 讲深入浅出索引(下)"></a>05 讲深入浅出索引(下)</h1><h2 id="回表过程"><a href="#回表过程" class="headerlink" title="回表过程"></a>回表过程</h2><p>在下面这个表T中，如果我执行 <strong>select * from T where k between 3 and 5</strong>，需要执行几次树的搜索操作，会扫描多少行？</p><p>下面是这个表的初始化语句。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create table T (</span><br><span class="line">ID int primary key,</span><br><span class="line">k int NOT NULL DEFAULT 0, </span><br><span class="line">s varchar(16) NOT NULL DEFAULT &#x27;&#x27;,</span><br><span class="line">index k(k))</span><br><span class="line">engine=InnoDB;</span><br><span class="line"></span><br><span class="line">insert into T values(100,1, &#x27;aa&#x27;),(200,2,&#x27;bb&#x27;),(300,3,&#x27;cc&#x27;),(500,5,&#x27;ee&#x27;),(600,6,&#x27;ff&#x27;),(700,7,&#x27;gg&#x27;);</span><br></pre></td></tr></table></figure><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230921102234370.png" alt="image-20230921102234370"></p><p>现在，我们一起来看看这条SQL查询语句的执行流程：</p><ol><li>在k索引树上找到k&#x3D;3的记录，取得 ID &#x3D; 300；</li><li>再到ID索引树查到ID&#x3D;300对应的R3；</li><li>在k索引树取下一个值k&#x3D;5，取得ID&#x3D;500；</li><li>再回到ID索引树查到ID&#x3D;500对应的R4；</li><li>在k索引树取下一个值k&#x3D;6，不满足条件，循环结束。</li></ol><p>在这个过程中，<strong>回到主键索引树搜索的过程，我们称为回表</strong>。可以看到，这个查询过程读了k索引树的3条记录（步骤1、3和5），回表了两次（步骤2和4）。</p><p>有没有可能经过索引优化，避免回表过程呢？</p><h2 id="覆盖索引"><a href="#覆盖索引" class="headerlink" title="覆盖索引"></a>覆盖索引</h2><p>如果执行的语句是select <strong>ID</strong> from T where k between 3 and 5，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为覆盖索引。</p><p><strong>由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。</strong></p><p>需要注意的是，在<strong>引擎内部</strong>使用覆盖索引在索引k上其实读了<strong>三个记录</strong>，R3~R5（对应的索引k上的记录项），但是对于MySQL的<strong>Server层</strong>来说，它就是找引擎拿到了<strong>两条记录</strong>，因此MySQL认为扫描行数是2。</p><h2 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h2><p><strong>B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录。</strong></p><p><strong>第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。</strong></p><p>第二要<strong>考虑的原则就是空间</strong>了。比如name字段是比age字段大的 ，那我就建议你创建一个（name,age)的联合索引和一个(age)的单字段索引。</p><h2 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a>索引下推</h2><p>上一段我们说到满足最左前缀原则的时候，最左前缀可以用于在索引中定位记录。这时，你可能要问，那些不符合最左前缀的部分，会怎么样呢？</p><p>我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是10岁的所有男孩”。那么，SQL语句是这么写的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from tuser where name like &#x27;张%&#x27; and age=10 and ismale=1;</span><br></pre></td></tr></table></figure><p>你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录ID3。当然，这还不错，总比全表扫描要好。</p><p>然后呢？</p><p>当然是判断其他条件是否满足。</p><p>在MySQL 5.6之前，只能从ID3开始一个个回表。到主键索引上找出数据行，再对比字段值。</p><p>而MySQL 5.6 引入<strong>的索引下推优化</strong>（index condition pushdown)， 可以<strong>在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数</strong>。</p><p>索引下推是使用联合索引时，若是后面的索引失效，就可以使用索引下推</p><p><strong>总结：</strong><br>回表：回到主键索引树搜索的过程，称为回表<br>覆盖索引：某索引已经覆盖了查询需求，称为覆盖索引，例如：select ID from T where k between 3 and 5<br>在引擎内部使用覆盖索引在索引K上其实读了三个记录，R3~R5(对应的索引k上的记录项)，但对于MySQL的Server层来说，它就是找引擎拿到了两条记录，因此MySQL认为扫描行数是2</p><p>最左前缀原则：B+Tree这种索引结构，可以利用索引的”最左前缀”来定位记录<br>只要满足最左前缀，就可以利用索引来加速检索。<br>最左前缀可以是联合索引的最左N个字段，也可以是字符串索引的最左M个字符<br>第一原则是：如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。</p><p>索引下推：在MySQL5.6之前，只能从根据最左前缀查询到ID开始一个个回表。到主键索引上找出数据行，再对比字段值。<br>MySQL5.6引入的索引下推优化，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p><h1 id="06-讲全局锁和表锁：给表加个字段怎么有这么多阻碍"><a href="#06-讲全局锁和表锁：给表加个字段怎么有这么多阻碍" class="headerlink" title="06 讲全局锁和表锁：给表加个字段怎么有这么多阻碍"></a>06 讲全局锁和表锁：给表加个字段怎么有这么多阻碍</h1><p><strong>根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类</strong>。</p><h2 id="全局锁"><a href="#全局锁" class="headerlink" title="全局锁"></a>全局锁</h2><p>顾名思义，全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。</p><p><strong>全局锁的典型使用场景是，做全库逻辑备份。</strong>也就是把整库每个表都select出来存成文本。</p><p>但是让整库都只读，听上去就很危险：</p><ul><li>如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；</li><li>如果你在从库上备份，那么备份期间从库不能执行主库同步过来的binlog，会导致主从延迟。</li></ul><p>官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。</p><p>你一定在疑惑，有了这个功能，为什么还需要FTWRL呢？<strong>一致性读是好，但前提是引擎要支持这个隔离级别。</strong>比如，对于MyISAM这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用FTWRL命令了。</p><p>所以，<strong>single-transaction方法只适用于所有的表使用事务引擎的库。</strong>如果有的表使用了不支持事务的引擎，那么备份就只能通过FTWRL方法。这往往是DBA要求业务开发人员使用InnoDB替代MyISAM的原因之一。</p><p>你也许会问，<strong>既然要全库只读，为什么不使用set global readonly&#x3D;true的方式呢</strong>？确实readonly方式也可以让全库进入只读状态，但我还是会建议你用FTWRL方式，主要有两个原因：</p><ul><li>一是，在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改global变量的方式影响面更大，我不建议你使用。</li><li>二是，在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。</li></ul><blockquote><p>我认为还有一个原因：修改global属性后，已有的session不会更改</p></blockquote><p>业务的更新不只是增删改数据（DML)，还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。</p><h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h2><p>MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。</p><p><strong>表锁的语法是 lock tables … read&#x2F;write。</strong></p><p><strong>另一类表级的锁是MDL（metadata lock)。</strong>MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。</p><p>因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。</p><ul><li>读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。</li><li>读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。</li></ul><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230921112908550.png" alt="image-20230921112908550"></p><p>我们可以看到session A先启动，这时候会对表t加一个MDL读锁。由于session B需要的也是MDL读锁，因此可以正常执行。</p><p>之后session C会被blocked，是因为session A的MDL读锁还没有释放，而session C需要MDL写锁，因此只能被<strong>阻塞</strong>。</p><p>如果只有session C自己被阻塞还没什么关系，但是之后所有要在表t上新申请MDL读锁的请求也会被session C阻塞。前面我们说了，所有对表的增删改查操作都需要先申请MDL读锁，就都被锁住，等于这个表现在完全不可读写了。</p><p><strong>解决方法：</strong></p><p>比较理想的机制是，<strong>在alter table语句里面设定等待时间</strong>，如果在这个指定的等待时间里面能够拿到MDL写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者DBA再通过重试命令重复这个过程。</p><p>MariaDB已经合并了AliSQL的这个功能，所以这两个开源分支目前都支持DDL NOWAIT&#x2F;WAIT n这个语法。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE tbl_name NOWAIT add column ...</span><br><span class="line">ALTER TABLE tbl_name WAIT N add column ... </span><br></pre></td></tr></table></figure><p><strong>总结：</strong></p><p>根据加锁范围：MySQL里面的锁可以分为：全局锁、表级锁、行级锁</p><p>一、全局锁：<br>对整个数据库实例加锁。<br>MySQL提供加全局读锁的方法：Flush tables with read lock(FTWRL)<br>这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。<br>使用场景：全库逻辑备份。<br>风险：<br>1.如果在主库备份，在备份期间不能更新，业务停摆<br>2.如果在从库备份，备份期间不能执行主库同步的binlog，导致主从延迟</p><p>官方自带的逻辑备份工具mysqldump，当mysqldump使用参数–single-transaction的时候，会启动一个事务，确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。</p><p>一致性读是好，但是前提是引擎要支持这个隔离级别。<br>如果要全库只读，为什么不使用set global readonly&#x3D;true的方式？<br>1.在有些系统中，readonly的值会被用来做其他逻辑，比如判断主备库。所以修改global变量的方式影响太大。<br>2.在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。</p><p>二、表级锁<br>MySQL里面表级锁有两种，一种是表锁，一种是元数据锁(meta data lock,MDL)<br>表锁的语法是:lock tables … read&#x2F;write<br>可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。<br>对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。</p><p>MDL：不需要显式使用，在访问一个表的时候会被自动加上。<br>MDL的作用：保证读写的正确性。<br>在对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。<br>读锁之间不互斥。读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。<br>MDL 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。</p><h1 id="07-讲行锁功过：怎么减少行锁对性能的影响"><a href="#07-讲行锁功过：怎么减少行锁对性能的影响" class="headerlink" title="07 讲行锁功过：怎么减少行锁对性能的影响"></a>07 讲行锁功过：怎么减少行锁对性能的影响</h1><p>MySQL的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如MyISAM引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。<strong>InnoDB是支持行锁的，这也是MyISAM被InnoDB替代的重要原因之一</strong>。</p><h2 id="两阶段锁"><a href="#两阶段锁" class="headerlink" title="两阶段锁"></a>两阶段锁</h2><p><strong>在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。</strong></p><p>知道了这个设定，对我们使用事务有什么帮助呢？那就是，<font color="red">如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放</font>。</p><blockquote><p>eg：</p><p>假设你负责实现一个电影票在线交易业务，顾客A要在影院B购买电影票。我们简化一点，这个业务需要涉及到以下操作：</p><ol><li>从顾客A账户余额中扣除电影票价；</li><li>给影院B的账户余额增加这张电影票价；</li><li>记录一条交易日志。</li></ol><p>也就是说，要完成这个交易，我们需要update两条记录，并insert一条记录。当然，为了保证交易的原子性，我们要把这三个操作放在一个事务中。那么，你会怎样安排这三个语句在事务中的顺序呢？</p><p>试想如果同时有另外一个顾客C要在影院B买票，那么这两个事务冲突的部分就是语句2了。因为它们要更新同一个影院账户的余额，需要修改同一行数据。</p><p>根据两阶段锁协议，不论你怎样安排语句顺序，所有的操作需要的行锁都是在事务提交的时候才释放的。所以，如果你把语句2安排在最后，比如按照3、1、2这样的顺序，那么影院账户余额这一行的锁时间就最少。这就最大程度地减少了事务之间的锁等待，<strong>提升了并发度</strong>。</p></blockquote><h2 id="死锁和死锁检测"><a href="#死锁和死锁检测" class="headerlink" title="死锁和死锁检测"></a>死锁和死锁检测</h2><p>如果这个影院做活动，可以低价预售一年内所有的电影票，而且这个活动只做一天。于是在活动时间开始的时候，你的MySQL就挂了。你登上服务器一看，CPU消耗接近100%，但整个数据库每秒就执行不到100个事务。这是什么原因呢？</p><p>这里，我就要说到<strong>死锁</strong>和<strong>死锁检测</strong>了。</p><p>当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。这里我用数据库中的行锁举个例子。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230922131553223.png" alt="image-20230922131553223"></p><p>这时候，事务A在等待事务B释放id&#x3D;2的行锁，而事务B在等待事务A释放id&#x3D;1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：</p><ul><li>一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。</li><li>另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。</li></ul><p>在InnoDB中，<strong>innodb_lock_wait_timeout的默认值是50s</strong>，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过50s才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是<strong>无法接受</strong>的。但是，我们又不可能直接把这个时间设置成一个很小的值，比如1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现<strong>很多误伤</strong>。</p><p>所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且<strong>innodb_deadlock_detect</strong>的默认值本身就是on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有<strong>额外负担</strong>的。</p><p>你可以想象一下这个过程：每当一个事务被锁的时候，就要看看它所依赖的线程有没有被别人锁住，如此循环，最后判断是否出现了循环等待，也就是死锁。</p><p>那如果是我们上面说到的所有事务都要更新同一行的场景呢？</p><p>每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是<strong>O(n)<strong>的操作。假设有</strong>1000</strong>个并发线程要同时更新同一行，那么死锁检测操作就是<strong>100万</strong>这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的CPU资源。因此，你就会看到<strong>CPU利用率很高，但是每秒却执行不了几个事务</strong>。</p><h2 id="怎么解决由热点行更新导致的性能问题？"><a href="#怎么解决由热点行更新导致的性能问题？" class="headerlink" title="怎么解决由热点行更新导致的性能问题？"></a>怎么解决由热点行更新导致的性能问题？</h2><p><font color="red">怎么解决由这种热点行更新导致的性能问题呢？</font></p><ul><li><strong>一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。</strong>但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是<strong>业务有损</strong>的。</li><li><strong>另一个思路是控制并发度。</strong>根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有10个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有600个客户端，这样即使每个客户端控制到只有5个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到3000。</li></ul><p>因此，这个<strong>并发控制要做在数据库服务端</strong>。如果你有<strong>中间件</strong>，可以考虑在中间件实现；如果你的团队有能修改MySQL源码的人，也可以做在MySQL里面。基本思路就是，对于相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。</p><p>可能你会问，<strong>如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？</strong></p><p>你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如10个记录，<strong>影院的账户总额等于这10个记录的值的总和</strong>。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的<strong>1&#x2F;10</strong>，可以减少锁等待个数，也就减少了死锁检测的CPU消耗。</p><p>这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成0的时候，代码要有特殊处理。</p><p><strong>总结：</strong></p><p>两阶段锁：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放， 而是要等到事务结束时才释放。<br>建议：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。</p><p>死锁：当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态。</p><p>解决方案：<br>1、通过参数 innodb_lock_wait_timeout 根据实际业务场景来设置超时时间，InnoDB引擎默认值是50s。<br>2、发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑（默认是开启状态）。</p><p>如何解决热点行更新导致的性能问题？<br>1、如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关闭掉。一般不建议采用<br>2、控制并发度，对应相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。<br>3、将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。</p><p><strong>innodb行级锁是通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。</strong></p><h1 id="08-讲事务到底是隔离的还是不隔离的"><a href="#08-讲事务到底是隔离的还是不隔离的" class="headerlink" title="08 讲事务到底是隔离的还是不隔离的"></a>08 讲事务到底是隔离的还是不隔离的</h1><h2 id="read-view的生成以及当前读"><a href="#read-view的生成以及当前读" class="headerlink" title="read view的生成以及当前读"></a>read view的生成以及当前读</h2><p>我给你举一个例子吧。下面是一个只有两行的表的初始化语句。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `k` int(11) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line">insert into t(id, k) values(1,1),(2,2);</span><br></pre></td></tr></table></figure><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/823acf76e53c0bdba7beab45e72e90d6.png" alt="img"></p><p>图1 事务A、B、C的执行流程</p><blockquote><p>这里，我们需要注意的是事务的启动时机。</p><p><strong>begin&#x2F;start transaction</strong> 命令并不是一个事务的起点，在执行到它们之后的<strong>第一个操作InnoDB表的语句（第一个快照读语句），事务才真正启动</strong>。如果你想要<strong>马上启动一个事务</strong>，可以使用<strong>start transaction with consistent snapshot</strong> 这个命令。</p><p>还需要注意的是，在整个专栏里面，我们的例子中如果没有特别说明，都是<strong>默认autocommit&#x3D;1</strong>。</p></blockquote><p>在这个例子中，事务C没有显式地使用begin&#x2F;commit，表示这个update语句本身就是一个事务，语句完成的时候会自动提交。事务B在更新了行之后查询; 事务A在一个只读事务中查询，并且时间顺序上是在事务B的查询之后。</p><p>这时，如果我告诉你<strong>事务B查到的k的值是3</strong>，而<strong>事务A查到的k的值是1</strong>，你是不是感觉有点晕呢？</p><h3 id="read-view原理"><a href="#read-view原理" class="headerlink" title="read view原理"></a>read view原理</h3><p>InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。</p><ul><li>数组里面事务ID的最小值记为<strong>低水位</strong>，当前系统里面已经创建过的事务ID的最大值加1记为<strong>高水位</strong>。</li><li>这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。</li><li>而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的。</li><li>这个视图数组把所有的row trx_id 分成了几种不同的情况。</li></ul><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230922142150072.png" alt="image-20230922142150072"></p><p><strong>read view规则：</strong></p><p>这样，对于当前事务的启动瞬间来说，一个数据版本的row trx_id，有以下几种可能：</p><ol><li>如果落在<strong>绿色部分</strong>，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的；</li><li>如果落在<strong>红色部分</strong>，表示这个版本是由将来启动的事务生成的，是肯定不可见的；</li><li>如果落在<strong>黄色部分</strong>，那就包括两种情况<br>a. 若 row trx_id<strong>在</strong>数组中，表示这个版本是由还没提交的事务生成的，不可见；<br>b. 若 row trx_id<strong>不在</strong>数组中，表示这个版本是已经提交了的事务生成的，可见。</li></ol><p><strong>InnoDB利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。</strong></p><p>所以上面那道例题的分析如下：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230922142355909.png" alt="image-20230922142355909"></p><p>现在事务A要来读数据了，它的视图数组是[99,100]。当然了，读数据都是从当前版本读起的。所以，事务A查询语句的读数据流程是这样的：</p><ul><li>找到(1,3)的时候，判断出row trx_id&#x3D;101，比高水位大，处于红色区域，不可见；</li><li>接着，找到上一个历史版本，一看row trx_id&#x3D;102，比高水位大，处于红色区域，不可见；</li><li>再往前找，终于找到了（1,1)，它的row trx_id&#x3D;90，比低水位小，处于绿色区域，可见。</li></ul><p>这样执行下来，虽然期间这一行数据被修改过，但是事务A不论在什么时候查询，看到这行数据的结果都是一致的，所以我们称之为一致性读。</p><h3 id="当前读"><a href="#当前读" class="headerlink" title="当前读"></a>当前读</h3><p>细心的同学可能有疑问了：<strong>事务B的update语句，如果按照一致性读，好像结果不对哦？</strong></p><p>你看图5中，事务B的视图数组是先生成的，之后事务C才提交，不是应该看不见(1,2)吗，怎么能算出(1,3)来？</p><blockquote><p>是的，如果事务B在更新之前查询一次数据，这个查询返回的k的值确实是1。</p><p>但是，当它要去更新数据的时候，就不能再在历史版本上更新了，否则事务C的更新就丢失了。因此，事务B此时的set k&#x3D;k+1是在（1,2）的基础上进行的操作。</p><p>所以，这里就用到了这样一条规则：<strong>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。</strong></p><p>因此，在更新的时候，当前读拿到的数据是(1,2)，更新后生成了新版本的数据(1,3)，这个新版本的row trx_id是101。</p><p>所以，在执行事务B查询语句的时候，一看自己的版本号是101，最新数据的版本号也是101，是自己的更新，可以直接使用，所以查询得到的k的值是3。</p><p>这里我们提到了一个概念，叫作当前读。其实，<strong>除了update语句外，select语句如果加锁，也是当前读。</strong></p></blockquote><p>READ VIEW分为快照读和当前读，**<font color="red">修改删除插入操作和加锁的select操作都属于当前读</font>**</p><p><strong>总结：</strong></p><p>1.innodb支持RC和RR隔离级别实现是用的一致性视图(consistent read view)</p><p>2.事务在启动时会拍一个快照,这个快照是基于整个库的.<br>基于整个库的意思就是说一个事务内,整个库的修改对于该事务都是不可见的(对于快照读的情况)</p><p>3.事务是如何实现的MVCC呢?<br>(1)每个事务都有一个事务ID,叫做transaction id(严格递增)<br>(2)事务在启动时,找到已提交的最大事务ID记为up_limit_id。<br>(3)事务在更新一条语句时,比如id&#x3D;1改为了id&#x3D;2.会把id&#x3D;1和该行之前的row trx_id写到undo log里,<br>并且在数据页上把id的值改为2,并且把修改这条语句的transaction id记在该行行头<br>(4)再定一个规矩,一个事务要查看一条数据时,必须先用该事务的up_limit_id与该行的transaction id做比对,<br>如果up_limit_id&gt;&#x3D;transaction id,那么可以看.如果up_limit_id&lt;transaction id,则只能去undo log里去取。去undo log查找数据的时候,也需要做比对,必须up_limit_id&gt;transaction id,才返回数据</p><p>4.什么是当前读,由于当前读都是<strong>先读后写</strong>,只能读当前的值,所以为当前读会更新事务内的up_limit_id为该事务的transaction id</p><p>5.为什么rr能实现可重复读而rc不能,分两种情况<br>(1)快照读的情况下,rr不能更新事务内的up_limit_id,<br>而rc每次会把up_limit_id更新为快照读之前最新已提交事务的transaction id,则rc不能可重复读<br>(2)当前读的情况下,rr是利用record lock+gap lock来实现的,而rc没有gap,所以rc不能可重复读</p><h1 id="09-讲普通索引和唯一索引，应该怎么选择"><a href="#09-讲普通索引和唯一索引，应该怎么选择" class="headerlink" title="09 讲普通索引和唯一索引，应该怎么选择"></a>09 讲普通索引和唯一索引，应该怎么选择</h1><p>在不同的业务场景下，应该选择普通索引，还是唯一索引？</p><p>假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证了不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似这样的SQL语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select name from CUser where id_card = &#x27;xxxxxxxyyyyyyzzzzz&#x27;;</span><br></pre></td></tr></table></figure><p>所以，你一定会考虑在id_card字段上建索引。</p><p>由于身份证号字段比较大，我不建议你把身份证号当做主键，那么现在你有两个选择，要么给id_card字段创建唯一索引，要么创建一个普通索引。如果业务代码已经保证了不会写入重复的身份证号，那么这两个选择逻辑上都是正确的。</p><p>现在我要问你的是，从性能的角度考虑，你选择唯一索引还是普通索引呢？选择的依据是什么呢？</p><h2 id="查询过程的区别"><a href="#查询过程的区别" class="headerlink" title="查询过程的区别"></a>查询过程的区别</h2><p>假设，执行查询的语句是 select id from T where k&#x3D;5。这个查询语句在索引树上查找的过程，先是通过B+树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。</p><ul><li>对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k&#x3D;5条件的记录。</li><li>对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。</li></ul><p>那么，这个不同带来的性能差距会有多少呢？答案是，<strong>微乎其微</strong>。</p><h2 id="更新过程的区别"><a href="#更新过程的区别" class="headerlink" title="更新过程的区别"></a>更新过程的区别</h2><h3 id="change-buffer"><a href="#change-buffer" class="headerlink" title="change buffer"></a>change buffer</h3><p>为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下change buffer。</p><p>当需要<strong>更新一个数据页</strong>时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些<strong>更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页</strong>了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。</p><p>需要说明的是，虽然名字叫作change buffer，实际上它是可以持久化的数据。也就是说，change buffer在内存中有拷贝，也会被写入到磁盘上。</p><p>将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了<strong>访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中</strong>，也会执行merge操作。</p><p>显然，如果能够将更新操作先记录在change buffer，<strong>减少读磁盘</strong>，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率。</p><p>那么，<strong>什么条件下可以使用change buffer呢？</strong></p><ul><li>对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入(4,400)这个记录，就要先判断现在表中是否已经存在k&#x3D;4的记录，而这必须要<strong>将数据页读入内存才能判断</strong>。如果都已经读入到内存了，那<strong>直接更新内存</strong>会更快，就没必要使用change buffer了。</li><li>因此，唯一索引的更新就不能使用change buffer，实际上也只有<strong>普通索引</strong>可以使用。</li></ul><p>change buffer用的是buffer pool里的内存，因此不能无限增大。change buffer的大小，可以通过参数<strong>innodb_change_buffer_max_size</strong>来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。</p><h3 id="更新区别"><a href="#更新区别" class="headerlink" title="更新区别"></a>更新区别</h3><p>现在，你已经理解了change buffer的机制，那么我们再一起来看看<strong>如果要在这张表中插入一个新记录(4,400)的话，InnoDB的处理流程是怎样的。</strong></p><p>第一种情况是，<strong>这个记录要更新的目标页在内存中</strong>。这时，InnoDB的处理流程如下：</p><ul><li>对于唯一索引来说，找到3和5之间的位置，判断到没有冲突，插入这个值，语句执行结束；</li><li>对于普通索引来说，找到3和5之间的位置，插入这个值，语句执行结束。</li></ul><p>这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的CPU时间。</p><p>但，这不是我们关注的重点。</p><p>第二种情况是，<strong>这个记录要更新的目标页不在内存中</strong>。这时，InnoDB的处理流程如下：</p><ul><li>对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；</li><li>对于普通索引来说，则是将更新记录在change buffer，语句执行就结束了。</li></ul><p>将数据从磁盘读入内存涉及<strong>随机IO的访问，是数据库里面成本最高的操作之一</strong>。change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。</p><p>之前我就碰到过一件事儿，有个DBA的同学跟我反馈说，他负责的某个业务的库内存命中率突然从99%降低到了75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，我发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引。</p><h2 id="change-buffer的使用场景"><a href="#change-buffer的使用场景" class="headerlink" title="change buffer的使用场景"></a>change buffer的使用场景</h2><p>使用change buffer对更新过程的加速作用，也清楚了change buffer只限于用在普通索引的场景下，而不适用于唯一索引。那么，现在有一个问题就是：普通索引的所有场景，使用change buffer都可以起到加速作用吗？</p><p>因为merge的时候是真正进行数据更新的时刻，而change buffer的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge之前，<strong>change buffer记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大</strong>。</p><ul><li>因此，对于<strong>写多读少</strong>的业务来说，页面在写完以后马上被访问到的概率比较小，此时<strong>change buffer的使用效果最好</strong>。这种业务模型常见的就是账单类、日志类的系统。</li><li>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，<strong>反而增加了change buffer的维护代价</strong>。所以，对于这种业务模式来说，change buffer反而起到了副作用。</li></ul><p>这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我<strong>建议你尽量选择普通索引</strong>。</p><p>如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭change buffer。而在其他情况下，change buffer都能提升更新性能。</p><p>使用普通索引：</p><ol><li>业务代码已经保证不会写入重复数据</li><li>归档库：归档数据已经是确保没有唯一键冲突了，要提高归档效率，可以考虑把表里面的唯一索引改成普通索引。</li></ol><h2 id="change-buffer-和-redo-log"><a href="#change-buffer-和-redo-log" class="headerlink" title="change buffer 和 redo log"></a>change buffer 和 redo log</h2><p>现在，我们要在表上执行这个插入语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; insert into t(id,k) values(id1,k1),(id2,k2);</span><br></pre></td></tr></table></figure><p>这里，我们假设当前k索引树的状态，查找到位置后，k1所在的数据页在内存(InnoDB buffer pool)中，k2所在的数据页不在内存中。如图2所示是带change buffer的更新状态图。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230924140201162.png" alt="image-20230924140201162"></p><p>分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。</p><p>这条更新语句做了如下的操作（按照图中的数字顺序）：</p><ol><li>Page 1在内存中，直接更新内存；</li><li>Page 2没有在内存中，就在内存的change buffer区域，记录下“我要往Page 2插入一行”这个信息</li><li>将上述两个动作记入redo log中（图中3和4）。</li></ol><p>比如，我们现在要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。</p><p>如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230924140252534.png" alt="image-20230924140252534"></p><p>从图中可以看到：</p><ol><li>读Page 1的时候，<strong>直接从内存返回</strong>。有几位同学在前面文章的评论中问到，WAL之后如果读数据，是不是一定要读盘，是不是一定要从redo log里面把数据更新以后才可以返回？其实是不用的。你可以看一下图3的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。</li><li>要读Page 2的时候，需要把Page 2从磁盘<strong>读入内存中，然后应用change buffer里面的操作日志</strong>，生成一个正确的版本并返回结果。</li></ol><p>可以看到，直到需要读Page 2的时候，这个数据页才会被读入内存。</p><p>所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，</p><ul><li><strong>redo log 主要节省的是<code>随机写</code>磁盘的IO消耗（转成顺序写）</strong></li><li><strong>而change buffer主要节省的则是<code>随机读</code>磁盘的IO消耗。</strong></li></ul><blockquote><p>注意：这里change buffer是针对<strong>insert</strong>操作的页更新，针对非唯一索引和唯一索引的<strong>update</strong>和<strong>delete</strong>而且条件是where 索引值&#x3D;这种情况，会采用锁定读，这时候要“<strong>先读后写</strong>”，读的时候数据会读入内存，更新的时候直接改内存，就<strong>不需要change buffer</strong>了</p></blockquote><p><strong>总结:</strong></p><p>选择普通索引还是唯一索引？<br>对于查询过程来说：<br>a、普通索引，查到满足条件的第一个记录后，继续查找下一个记录，知道第一个不满足条件的记录<br>b、唯一索引，由于索引唯一性，查到第一个满足条件的记录后，停止检索<br>但是，两者的性能差距微乎其微。因为InnoDB根据数据页来读写的。<br>对于更新过程来说：<br>概念：change buffer<br>当需要更新一个数据页，如果数据页在内存中就直接更新，如果不在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中。下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中的与这个页有关的操作。</p><p>change buffer是可以持久化的数据。在内存中有拷贝，也会被写入到磁盘上</p><p>purge:将change buffer中的操作应用到原数据页上，得到最新结果的过程，成为merge<br>访问这个数据页会触发merge，系统有后台线程定期merge，在数据库正常关闭的过程中，也会执行merge</p><p>唯一索引的更新不能使用change buffer</p><p>change buffer用的是buffer pool里的内存，change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。</p><p>将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。<br>change buffer 因为减少了随机磁盘访问，所以对更新性能的提升很明显。</p><p>change buffer使用场景<br>在一个数据页做purge之前，change buffer记录的变更越多，收益就越大。<br>对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。</p><p>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer,但之后由于马上要访问这个数据页，会立即触发purge过程。<br>这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来说，change buffer反而起到了副作用。</p><p>索引的选择和实践：<br>尽可能使用普通索引。<br>redo log主要节省的是随机写磁盘的IO消耗(转成顺序写)，而change buffer主要节省的则是随机读磁盘的IO消耗。</p><p>思考题：<br>change buffer不会丢失，因为change buffer是可以持久化的数据，在磁盘上占据了系统表空间ibdata，对应的内部系统表名为SYS_IBUF_TABLE，并且changebuffer的变更也会写入到redo log，因此在异常关机的时候，不会丢失。</p><h1 id="10-讲MySQL为什么有时候会选错索引"><a href="#10-讲MySQL为什么有时候会选错索引" class="headerlink" title="10 讲MySQL为什么有时候会选错索引"></a>10 讲MySQL为什么有时候会选错索引</h1><h2 id="MySQL选错索引举例"><a href="#MySQL选错索引举例" class="headerlink" title="MySQL选错索引举例"></a>MySQL选错索引举例</h2><p>前面我们介绍过索引，你已经知道了在MySQL中一张表其实是可以支持多个索引的。但是，你写SQL语句的时候，并没有主动指定使用哪个索引。也就是说，使用哪个索引是由MySQL来确定的。</p><p>不知道你有没有碰到过这种情况，一条本来可以执行得很快的语句，却由于MySQL选错了索引，而导致执行速度变得很慢？</p><p>我们一起来看一个例子吧。</p><p>我们先建一个简单的表，表里有a、b两个字段，并分别建上索引：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `a` int(11) DEFAULT NULL,</span><br><span class="line">  `b` int(11) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  KEY `a` (`a`),</span><br><span class="line">  KEY `b` (`b`)</span><br><span class="line">) ENGINE=InnoDB；</span><br></pre></td></tr></table></figure><p>然后，我们往表t中插入10万行记录，取值按整数递增，即：(1,1,1)，(2,2,2)，(3,3,3) 直到(100000,100000,100000)。</p><p>接下来，我们分析一条SQL语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t where a between 10000 and 20000;</span><br></pre></td></tr></table></figure><p>你一定会说，这个语句还用分析吗，很简单呀，a上有索引，肯定是要使用索引a的。</p><p>你说得没错，图1显示的就是使用explain命令看到的这条语句的执行情况。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/2cfce769551c6eac9bfbee0563d48fe3.png" alt="img"></p><p>从图1看上去，这条查询语句的执行也确实符合预期，key这个字段值是’a’，表示优化器选择了索引a。</p><p>不过别急，这个案例不会这么简单。在我们已经准备好的包含了10万行数据的表上，我们再做如下操作。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/1e5ba1c2934d3b2c0d96b210a27e1a1e.png" alt="img"></p><p>这里，session A的操作你已经很熟悉了，它就是开启了一个事务。随后，session B把数据都删除后，又调用了 idata这个存储过程，插入了10万行数据。</p><p>这时候，session B的查询语句select * from t where a between 10000 and 20000就不会再选择索引a了。我们可以通过慢查询日志（slow log）来查看一下具体的执行情况。</p><p>为了说明优化器选择的结果是否正确，我增加了一个对照，即：使用force index(a)来让优化器强制使用索引a（这部分内容，我还会在这篇文章的后半部分中提到）。</p><p>下面的三条SQL语句，就是这个实验过程。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">set long_query_time=0;</span><br><span class="line">select * from t where a between 10000 and 20000; /*Q1*/</span><br><span class="line">select * from t force index(a) where a between 10000 and 20000;/*Q2*/</span><br></pre></td></tr></table></figure><ul><li>第一句，是将慢查询日志的阈值设置为0，表示这个线程接下来的语句都会被记录入慢查询日志中；</li><li>第二句，Q1是session B原来的查询；</li><li>第三句，Q2是加了force index(a)来和session B原来的查询语句执行情况对比。</li></ul><p>如图3所示是这三条SQL语句执行完成后的慢查询日志。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/7c58b9c71853b8bba1a8ad5e926de1f6.png" alt="img"></p><p>可以看到，Q1扫描了10万行，显然是走了全表扫描，执行时间是40毫秒。Q2扫描了10001行，执行了21毫秒。也就是说，我们在没有使用force index的时候，MySQL用错了索引，导致了更长的执行时间。</p><p>这个例子对应的是我们平常不断地删除历史数据和新增数据的场景。这时，MySQL竟然会选错索引，是不是有点奇怪呢？今天，我们就从这个奇怪的结果说起吧。</p><h2 id="优化器的逻辑"><a href="#优化器的逻辑" class="headerlink" title="优化器的逻辑"></a>优化器的逻辑</h2><p>在第一篇文章中，我们就提到过，选择索引是优化器的工作。</p><p>而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少。</p><p>当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。</p><p>我们这个简单的查询语句并没有涉及到临时表和排序，所以MySQL选错索引肯定是在判断扫描行数的时候出问题了。</p><p>那么，问题就是：<strong>扫描行数是怎么判断的？</strong></p><p>MySQL在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。</p><p>这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。</p><p>我们可以使用show index方法，看到一个索引的基数。如图4所示，就是表t的show index 的结果 。虽然这个表的每一行的三个字段值都是一样的，但是在统计信息中，这三个索引的基数值并不同，而且其实都不准确。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/16dbf8124ad529fec0066950446079d4.png" alt="img"></p><h3 id="基数统计方法"><a href="#基数统计方法" class="headerlink" title="基数统计方法"></a>基数统计方法</h3><p>那么，<strong>MySQL是怎样得到索引的基数的呢？</strong>这里，我给你简单介绍一下MySQL采样统计的方法。</p><p>为什么要采样统计呢？因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。</p><p>采样统计的时候，InnoDB默认会选择<strong>N个数据页</strong>，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。</p><p>而数据表是会持续更新的，索引统计信息也不会固定不变。所以，当变更的数据行数超过<strong>1&#x2F;M</strong>的时候，会自动触发重新做一次索引统计。</p><p>在MySQL中，有两种存储索引统计的方式，可以通过设置参数<strong>innodb_stats_persistent</strong>的值来选择：</p><ul><li>设置为<strong>on</strong>的时候，表示统计信息会持久化存储。这时，默认的N是20，M是10。</li><li>设置为<strong>off</strong>的时候，表示统计信息只存储在内存中。这时，默认的N是8，M是16。</li></ul><p>由于是采样统计，所以不管N是20还是8，这个基数都是很容易不准的。</p><p>你可以从图4中看到，这次的索引统计值（cardinality列）虽然不够精确，但大体上还是差不多的，选错索引一定还有别的原因。</p><h3 id="预估扫描行数"><a href="#预估扫描行数" class="headerlink" title="预估扫描行数"></a>预估扫描行数</h3><p>其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。</p><p>接下来，我们再一起看看优化器预估的，这两个语句的扫描行数是多少。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/e2bc5f120858391d4accff05573e1289.png" alt="img"></p><p>图5 意外的explain结果</p><p>rows这个字段表示的是预计扫描行数。</p><p>其中，Q1的结果还是符合预期的，rows的值是104620；<strong>但是Q2的rows值是37116，偏差就大了</strong>。而图1中我们用explain命令看到的rows是只有10001行，<strong>是这个偏差误导了优化器的判断</strong>。</p><p>到这里，可能你的第一个疑问不是为什么不准，而是优化器为什么放着扫描37000行的执行计划不用，却选择了扫描行数是100000的执行计划呢？</p><p>这是因为，如果使用索引a，每次从索引a上拿到一个值，都要回到主键索引上查出整行数据，这个代价优化器也要算进去的。</p><p>而如果选择扫描10万行，是直接在主键索引上扫描的，没有额外的代价。</p><p>优化器会估算这两个选择的代价，从结果看来，优化器认为直接扫描主键索引更快。当然，从执行时间看来，这个选择并不是最优的。</p><p>使用普通索引需要把回表的代价算进去，在图1执行explain的时候，也考虑了这个策略的代价 ，但图1的选择是对的。也就是说，这个策略并没有问题。</p><p>所以冤有头债有主，MySQL选错索引，这件事儿还得归咎到没能准确地判断出扫描行数。</p><blockquote><p><strong>为什么会得到错误的扫描行数？</strong></p><p>1.为什么没有session A,session B扫描的行数是1W<br>由于mysql是使用标记删除来删除记录的,并不从索引和数据文件中真正的删除。<br>如果delete和insert中间的间隔相对较小,purge线程还没有来得及清理该记录。<br>如果主键相同的情况下,<strong>新插入的insert会沿用之前删除的delete的记录的空间</strong>。<br>由于相同的数据量以及表大小,所以导致了统计信息没有变化<br>2.为什么开启了session A,session B扫描行数变成3W<br>由于session A开启了一致性读,目的为了保证session A的可重复读,insert只能<br>另起炉灶,<strong>不能占用delete的空间</strong>。所以出现的情况就是delete虽然删除了,但是<br>未释放空间,insert又增加了空间。导致统计信息有误</p><p>delete 语句删掉了所有的数据，然后再通过call idata()插入了10万行数据，看上去是覆盖了原来的10万行。</p><p>但是，session A开启了事务并没有提交，所以之前插入的10万行数据是不能删除的。这样，之前的数据每一行数据都有两个版本，旧版本是delete之前的数据，新版本是标记为deleted的数据。</p><p>这样，索引a上的数据其实就有两份。</p><p>然后你会说，不对啊，主键上的数据也不能删，那没有使用force index的语句，使用explain命令看到的扫描行数为什么还是100000左右？（潜台词，如果这个也翻倍，也许优化器还会认为选字段a作为索引更合适）</p><p>是的，不过这个是主键，主键是直接按照表的行数来估计的。而表的行数，优化器直接用的是show table status的值。</p></blockquote><h3 id="修正统计信息"><a href="#修正统计信息" class="headerlink" title="修正统计信息"></a>修正统计信息</h3><p>既然是统计信息不对，那就修正。analyze table t 命令，可以用来重新统计索引信息。我们来看一下执行效果。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">analyze table t;</span><br></pre></td></tr></table></figure><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/209e9d3514688a3bcabbb75e54e1e49c.png" alt="img"></p><p>图6 执行analyze table t 命令恢复的explain结果</p><p>这回对了。</p><p>所以在实践中，如果你发现explain的结果预估的rows值跟实际情况差距比较大，可以采用这个方法来处理。</p><p>其实，如果只是索引统计不准确，通过analyze命令可以解决很多问题，但是前面我们说了，优化器可不止是看扫描行数。</p><h3 id="第二个例子"><a href="#第二个例子" class="headerlink" title="第二个例子"></a>第二个例子</h3><p>依然是基于这个表t，我们看看另外一个语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;</span><br></pre></td></tr></table></figure><p>从条件上看，这个查询没有符合条件的记录，因此会返回空集合。</p><p>在开始执行这条语句之前，你可以先设想一下，如果你来选择索引，会选择哪一个呢？</p><p>为了便于分析，我们先来看一下a、b这两个索引的结构图。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230924143943300.png" alt="image-20230924143943300"></p><p>图7 a、b索引的结构图</p><p>如果使用索引a进行查询，那么就是扫描索引a的前1000个值，然后取到对应的id，再到主键索引上去查出每一行，然后根据字段b来过滤。显然这样需要扫描1000行。</p><p>如果使用索引b进行查询，那么就是扫描索引b的最后50001个值，与上面的执行过程相同，也是需要回到主键索引上取值再判断，所以需要扫描50001行。</p><p>所以你一定会想，如果使用索引a的话，执行速度明显会快很多。那么，下面我们就来看看到底是不是这么一回事儿。</p><p>图8是执行explain的结果。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; explain select * from t where (a between 1 and 1000) and (b between 50000 and 100000) order by b limit 1;</span><br></pre></td></tr></table></figure><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/483bcb1ef3bb902844e80d9cbdd73ab8.png" alt="img"></p><p>图8 使用explain方法查看执行计划 2</p><p>可以看到，返回结果中key字段显示，这次优化器选择了索引b，而rows字段显示需要扫描的行数是50198。</p><p>从这个结果中，你可以得到两个结论：</p><ol><li>扫描行数的估计值依然不准确；</li><li>这个例子里MySQL又选错了索引。</li></ol><h2 id="索引选择异常和处理"><a href="#索引选择异常和处理" class="headerlink" title="索引选择异常和处理"></a>索引选择异常和处理</h2><p>其实大多数时候优化器都能找到正确的索引，但偶尔你还是会碰到我们上面举例的这两种情况：原本可以执行得很快的SQL语句，执行速度却比你预期的慢很多，你应该怎么办呢？</p><p><strong>一种方法是，像我们第一个例子一样，采用force index强行选择一个索引。</strong>MySQL会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。如果force index指定的索引在候选索引列表中，就直接选择这个索引，不再评估其他索引的执行代价。</p><p>我们来看看第二个例子。刚开始分析时，我们认为选择索引a会更好。现在，我们就来看看执行效果：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/9582401a6bed6cb8fd803c9555750b54.png" alt="img"></p><p>可以看到，原本语句需要执行2.23秒，而当你使用force index(a)的时候，只用了0.05秒，比优化器的选择快了40多倍。</p><p>也就是说，优化器没有选择正确的索引，force index起到了“矫正”的作用。</p><p>不过很多程序员不喜欢使用force index，一来这么写不优美，二来如果索引改了名字，这个语句也得改，显得很麻烦。而且如果以后迁移到别的数据库的话，这个语法还可能会不兼容。</p><p>但其实使用force index最主要的问题还是变更的及时性。因为选错索引的情况还是比较少出现的，所以开发的时候通常不会先写上force index。而是等到线上出现问题的时候，你才会再去修改SQL语句、加上force index。但是修改之后还要测试和发布，对于生产系统来说，这个过程不够敏捷。</p><p>所以，数据库的问题最好还是在数据库内部来解决。那么，在数据库里面该怎样解决呢？</p><p>既然优化器放弃了使用索引a，说明a还不够合适，所以<strong>第二种方法就是，我们可以考虑修改语句，引导MySQL使用我们期望的索引。</strong>比如，在这个例子里，显然把“order by b limit 1” 改成 “order by b,a limit 1” ，语义的逻辑是相同的。</p><p>我们来看看改之后的效果：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/14cd598e52a2b72dd334a42603e5b894.png" alt="img"></p><p>图10 order by b,a limit 1 执行结果</p><p>之前优化器选择使用索引b，是因为它认为使用索引b可以避免排序（b本身是索引，已经是有序的了，如果选择索引b的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。</p><p>现在order by b,a 这种写法，要求按照b,a排序，就意味着使用这两个索引都需要排序。因此，扫描行数成了影响决策的主要条件，于是此时优化器选了只需要扫描1000行的索引a。</p><p>当然，这种修改并不是通用的优化手段，只是刚好在这个语句里面有limit 1，因此如果有满足条件的记录， order by b limit 1和order by b,a limit 1 都会返回b是最小的那一行，逻辑上一致，才可以这么做。</p><p>如果你觉得修改语义这件事儿不太好，这里还有一种改法，图11是执行效果。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from  (select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 100)alias limit 1;</span><br></pre></td></tr></table></figure><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/b1a2ad43c78477d7f93dbc692cbaa0d7.png" alt="img"></p><p>图11 改写SQL的explain</p><p>在这个例子里，我们用limit 100让优化器意识到，使用b索引代价是很高的。其实是我们根据数据特征诱导了一下优化器，也不具备通用性。</p><p><strong>第三种方法是，在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。</strong></p><p>不过，在这个例子中，我没有找到通过新增索引来改变优化器行为的方法。这种情况其实比较少，尤其是经过DBA索引优化过的库，再碰到这个bug，找到一个更合适的索引一般比较难。</p><p>如果我说还有一个方法是删掉索引b，你可能会觉得好笑。但实际上我碰到过两次这样的例子，最终是DBA跟业务开发沟通后，发现这个优化器错误选择的索引其实根本没有必要存在，于是就删掉了这个索引，优化器也就重新选择到了正确的索引。</p><h1 id="11-讲怎么给字符串字段加索引"><a href="#11-讲怎么给字符串字段加索引" class="headerlink" title="11 讲怎么给字符串字段加索引"></a>11 讲怎么给字符串字段加索引</h1><h2 id="字符串前缀索引"><a href="#字符串前缀索引" class="headerlink" title="字符串前缀索引"></a>字符串前缀索引</h2><p>现在，几乎所有的系统都支持邮箱登录，如何在邮箱这样的字段上建立合理的索引，是我们今天要讨论的问题。</p><p>假设，你现在维护一个支持邮箱登录的系统，用户表是这么定义的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create table SUser(</span><br><span class="line">ID bigint unsigned primary key,</span><br><span class="line">email varchar(64), </span><br><span class="line">... </span><br><span class="line">)engine=innodb; </span><br></pre></td></tr></table></figure><p>由于要使用邮箱登录，所以业务代码中一定会出现类似于这样的语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select f1, f2 from SUser where email=&#x27;xxx&#x27;;</span><br></pre></td></tr></table></figure><p>从第4和第5篇讲解索引的文章中，我们可以知道，如果email这个字段上没有索引，那么这个语句就只能做全表扫描。</p><p>同时，MySQL是支持前缀索引的，也就是说，你可以<strong>定义字符串的一部分作为索引</strong>。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。</p><p>比如，这两个在email字段上创建索引的语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; alter table SUser add index index1(email);</span><br><span class="line">或</span><br><span class="line">mysql&gt; alter table SUser add index index2(email(6));</span><br></pre></td></tr></table></figure><p>第一个语句创建的index1索引里面，包含了每个记录的整个字符串；而第二个语句创建的index2索引里面，对于每个记录都是只取前6个字节。</p><p>那么，这两种不同的定义在数据结构和存储上有什么区别呢？如图2和3所示，就是这两个索引的示意图。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230925162512042.png" alt="image-20230925162512042"></p><p>从图中你可以看到，由于email(6)这个索引结构中每个邮箱字段都只取前6个字节（即：zhangs），所以<strong>占用的空间会更小</strong>，这就是使用前缀索引的优势。</p><blockquote><p>执行时：使用前缀索引会一直回表进行判断，<strong>增加了回表次数</strong>，在此例中，要回主键索引取4次数据，也就是扫描了4行。</p><p>而使用完全索引只用扫描一行</p><p>通过这个对比，你很容易就可以发现，<strong>使用前缀索引后，可能会导致查询语句读数据的次数变多</strong>。</p></blockquote><p>但是，对于这个查询语句来说，如果你定义的index2不是email(6)而是email(7），也就是说取email字段的前7个字节来构建索引的话，即满足前缀’zhangss’的记录只有一个，也能够直接查到ID2，只扫描一行就结束了。</p><p>也就是说<strong>使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。</strong></p><h2 id="怎么定义好前缀索引"><a href="#怎么定义好前缀索引" class="headerlink" title="怎么定义好前缀索引"></a>怎么定义好前缀索引</h2><p>于是，你就有个问题：当要给字符串创建前缀索引时，有什么方法能够确定我应该使用多长的前缀呢？</p><p>实际上，我们在建立索引时关注的是区分度，<strong>区分度越高越好</strong>。因为区分度越高，意味着重复的键值越少。因此，我们可以通过统计索引上有多少个不同的值来判断要使用多长的前缀。</p><p>首先，你可以使用下面这个语句，算出这个列上有多少个不同的值：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select count(distinct email) as L from SUser;</span><br></pre></td></tr></table></figure><p>然后，依次选取不同长度的前缀来看这个值，比如我们要看一下4~7个字节的前缀索引，可以用这个语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select </span><br><span class="line">  count(distinct left(email,4)）as L4,</span><br><span class="line">  count(distinct left(email,5)）as L5,</span><br><span class="line">  count(distinct left(email,6)）as L6,</span><br><span class="line">  count(distinct left(email,7)）as L7,</span><br><span class="line">from SUser;</span><br></pre></td></tr></table></figure><p>当然，使用前缀索引很可能会损失区分度，所以你需要预先设定一个可以接受的损失比例，比如5%。然后，在返回的L4~L7中，找出不小于 L * 95%的值，假设这里L6、L7都满足，你就可以选择前缀长度为6。</p><h2 id="前缀索引对覆盖索引的影响"><a href="#前缀索引对覆盖索引的影响" class="headerlink" title="前缀索引对覆盖索引的影响"></a>前缀索引对覆盖索引的影响</h2><p>前面我们说了使用前缀索引可能会增加扫描行数，这会影响到性能。其实，前缀索引的影响不止如此，我们再看一下另外一个场景。</p><p>你先来看看这个SQL语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id,email from SUser where email=&#x27;zhangssxyz@xxx.com&#x27;;</span><br></pre></td></tr></table></figure><p>与前面例子中的SQL语句</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id,name,email from SUser where email=&#x27;zhangssxyz@xxx.com&#x27;;</span><br></pre></td></tr></table></figure><p>相比，这个语句只要求返回id和email字段。</p><p>所以，如果使用index1（即email整个字符串的索引结构）的话，可以利用覆盖索引，从index1查到结果后直接就返回了，不需要回到ID索引再去查一次。而如果使用index2（即email(6)索引结构）的话，就不得不回到ID索引再去判断email字段的值。</p><p>即使你将index2的定义修改为email(18)的前缀索引，这时候虽然index2已经包含了所有的信息，但InnoDB还是要回到id索引再查一下，因为系统并不确定前缀索引的定义是否截断了完整信息。</p><p>也就是说，使用前缀索引就用不上覆盖索引对查询性能的优化了，这也是你在选择是否使用前缀索引时需要考虑的一个因素。</p><blockquote><p>使用前缀索引，就算包含了要查询的所有字段，也都会回表，<strong>不能使用覆盖索引</strong></p></blockquote><h2 id="定义字符串索引的其他方式"><a href="#定义字符串索引的其他方式" class="headerlink" title="定义字符串索引的其他方式"></a>定义字符串索引的其他方式</h2><p>假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为6的前缀索引的话，这个索引的区分度就非常低了。</p><p>按照我们前面说的方法，可能你需要创建长度为12以上的前缀索引，才能够满足区分度要求。</p><p>但是，索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。</p><p>那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。</p><p>答案是，有的。</p><h3 id="倒序存储"><a href="#倒序存储" class="headerlink" title="倒序存储"></a>倒序存储</h3><p>如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select field_list from t where id_card = reverse(&#x27;input_id_card_string&#x27;);</span><br></pre></td></tr></table></figure><p>由于身份证号的最后6位没有地址码这样的重复逻辑，所以最后这6位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用count(distinct)方法去做个验证。</p><h3 id="hash字段"><a href="#hash字段" class="headerlink" title="hash字段"></a>hash字段</h3><p>你可以在表上再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; alter table t add id_card_crc int unsigned, add index(id_card_crc);</span><br></pre></td></tr></table></figure><p>然后每次插入新记录的时候，都同时用crc32()这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过crc32()函数得到的结果可能是相同的，所以你的查询语句where部分要判断id_card的值是否精确相同。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select field_list from t where id_card_crc=crc32(&#x27;input_id_card_string&#x27;) and id_card=&#x27;input_id_card_string&#x27;</span><br></pre></td></tr></table></figure><p>这样，索引的长度变成了<strong>4个字节</strong>，比原来小了很多。</p><h3 id="倒序和hash的异同"><a href="#倒序和hash的异同" class="headerlink" title="倒序和hash的异同"></a>倒序和hash的异同</h3><p>接下来，我们再一起看看<strong>使用倒序存储和使用hash字段这两种方法的异同点。</strong></p><p><strong>相同点：</strong></p><p>都<strong>不支持范围查询</strong></p><ul><li>倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在[ID_X, ID_Y]的所有市民了。同样地，hash字段的方式也只能支持等值查询。</li></ul><p>它们的<strong>区别</strong>，主要体现在以下三个方面：</p><ol><li>从占用的额外空间来看，<strong>倒序</strong>存储方式在主键索引上，<strong>不会消耗额外的存储空间</strong>，而<strong>hash</strong>字段方法<strong>需要增加一个字段</strong>。当然，倒序存储方式使用4个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个hash字段的int类型也差不多抵消了。</li><li>在CPU消耗方面，倒序方式每次写和读的时候，都需要额外调用一次reverse函数，而hash字段的方式需要额外调用一次crc32()函数。如果只从这两个函数的计算复杂度来看的话，<strong>reverse函数额外消耗的CPU资源会更小些</strong>。</li><li>从查询效率上看，使用<strong>hash</strong>字段方式的查询性能相对<strong>更稳定一些</strong>。因为crc32算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。</li></ol><h1 id="12-讲为什么我的MySQL会“抖”一下"><a href="#12-讲为什么我的MySQL会“抖”一下" class="headerlink" title="12 讲为什么我的MySQL会“抖”一下"></a>12 讲为什么我的MySQL会“抖”一下</h1><p>平时的工作中，不知道你有没有遇到过这样的场景，一条SQL语句，正常执行的时候特别快，但是有时也不知道怎么回事，它就会变得特别慢，并且这样的场景很难复现，它不只随机，而且持续时间还很短。</p><p>看上去，这就像是数据库“抖”了一下。今天，我们就一起来看一看这是什么原因。</p><h2 id="为什么会突然变慢？"><a href="#为什么会突然变慢？" class="headerlink" title="为什么会突然变慢？"></a>为什么会突然变慢？</h2><p>在前面第2篇文章<a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/68633">《日志系统：一条SQL更新语句是如何执行的？》</a>中，我为你介绍了WAL机制。现在你知道了，InnoDB在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作redo log（重做日志），也就是《孔乙己》里咸亨酒店掌柜用来记账的粉板，在更新内存写完redo log后，就返回给客户端，本次更新成功。</p><p>做下类比的话，掌柜记账的账本是数据文件，记账用的粉板是日志文件（redo log），掌柜的记忆就是内存。</p><p>掌柜总要找时间把账本更新一下，这对应的就是把内存里的数据写入磁盘的过程，术语就是flush。在这个flush操作执行之前，孔乙己的赊账总额，其实跟掌柜手中账本里面的记录是不一致的。因为孔乙己今天的赊账金额还只在粉板上，而账本里的记录是老的，还没把今天的赊账算进去。</p><p><strong>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”</strong>。</p><p>不论是脏页还是干净页，都在内存中。在这个例子里，内存对应的就是掌柜的记忆。</p><p>接下来，我们用一个示意图来展示一下“孔乙己赊账”的整个操作过程。假设原来孔乙己欠账10文，这次又要赊9文。</p><p><strong>回到文章开头的问题，你不难想象，平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。</strong></p><h2 id="什么时候会flush"><a href="#什么时候会flush" class="headerlink" title="什么时候会flush"></a>什么时候会flush</h2><p>那么，什么情况会引发数据库的flush过程呢？</p><ul><li>第一种场景是，<strong>粉板满了，记不下了</strong>。这时候如果再有人来赊账，掌柜就只得放下手里的活儿，将粉板上的记录擦掉一些，留出空位以便继续记账。当然在擦掉之前，他必须先将正确的账目记录到账本中才行。<br>这个场景，对应的就是<strong>InnoDB的redo log写满了</strong>。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。</li></ul><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)实战45讲笔记.assets/image-20230925165033023.png" alt="image-20230925165033023" style="zoom:50%"><p>checkpoint可不是随便往前修改一下位置就可以的。比如图2中，把checkpoint位置从CP推进到CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都flush到磁盘上。之后，图中从write pos到CP’之间就是可以再写入的redo log的区域。</p><ul><li><p>第二种场景是，这一天生意太好，要记住的事情太多，掌柜发现自己快记不住了，赶紧找出账本把孔乙己这笔账先加进去。<br>这种场景，对应的就是<strong>系统内存不足</strong>。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。<strong>如果淘汰的是“脏页”，就要先将脏页写到磁盘</strong>。<br>你一定会说，这时候难道不能直接把内存淘汰掉，下次需要请求的时候，从磁盘读入数据页，然后拿redo log出来应用不就行了？这里其实是从性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：</p><ul><li>一种是内存里存在，内存里就肯定是正确的结果，直接返回；</li><li>另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。这样的效率最高。</li></ul></li><li><p>第三种场景是，生意不忙的时候，或者打烊之后。这时候柜台没事，掌柜闲着也是闲着，不如更新账本。<br>这种场景，对应的就是MySQL认为<strong>系统“空闲”的时候</strong>。当然，MySQL“这家酒店”的生意好起来可是会很快就能把粉板记满的，所以“掌柜”要合理地安排时间，即使是“生意好”的时候，也要见缝插针地找时间，只要有机会就刷一点“脏页”。</p></li><li><p>第四种场景是，年底了咸亨酒店要关门几天，需要把账结清一下。这时候掌柜要把所有账都记到账本上，这样过完年重新开张的时候，就能就着账本明确账目情况了。<br>这种场景，对应的就是<strong>MySQL正常关闭的情况</strong>。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。</p></li></ul><h2 id="flush操作对系统性能的影响"><a href="#flush操作对系统性能的影响" class="headerlink" title="flush操作对系统性能的影响"></a>flush操作对系统性能的影响</h2><p>其中，第三种情况是属于MySQL空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，你不会太关注“性能”问题。所以这里，我们主要来分析一下前两种场景下的性能问题。</p><p>第一种是“<strong>redo log写满了，要flush脏页</strong>”，<strong>这种情况是InnoDB要尽量避免的</strong>。因为出现这种情况的时候，整个系统就<strong>不能再接受更新</strong>了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为0。</p><p>第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。<strong>InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：</strong></p><ul><li>第一种是，还没有使用的；</li><li>第二种是，使用了并且是干净页；</li><li>第三种是，使用了并且是脏页。</li></ul><p>InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。</p><p>而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。</p><p>所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显<strong>影响性能</strong>的：</p><ol><li><strong>一个查询要淘汰的脏页个数太多</strong>，会导致查询的响应时间明显变长；</li><li><strong>日志写满</strong>，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。</li></ol><p>所以，InnoDB需要有控制脏页比例的机制，来尽量避免上面的这两种情况。</p><h2 id="InnoDB刷脏页速度的控制策略"><a href="#InnoDB刷脏页速度的控制策略" class="headerlink" title="InnoDB刷脏页速度的控制策略"></a>InnoDB刷脏页速度的控制策略</h2><h3 id="主机IO能力"><a href="#主机IO能力" class="headerlink" title="主机IO能力"></a>主机IO能力</h3><p>接下来，我就来和你说说InnoDB脏页的控制策略，以及和这些策略相关的参数。</p><p>首先，你要正确地告诉InnoDB所在主机的IO能力，这样InnoDB才能知道需要全力刷脏页的时候，可以刷多快。</p><p>这就要用到<strong>innodb_io_capacity</strong>这个参数了，它会告诉InnoDB你的磁盘能力。这个值我建议你设置成磁盘的IOPS。磁盘的IOPS可以通过fio这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest</span><br></pre></td></tr></table></figure><p>其实，因为没能正确地设置innodb_io_capacity参数，而导致的性能问题也比比皆是。之前，就曾有其他公司的开发负责人找我看一个库的性能问题，说MySQL的写入速度很慢，TPS很低，但是数据库主机的IO压力并不大。经过一番排查，发现罪魁祸首就是这个参数的设置出了问题。</p><p>他的主机磁盘用的是SSD，但是innodb_io_capacity的值设置的是300。于是，InnoDB认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。</p><p>虽然我们现在已经定义了“全力刷脏页”的行为，但平时总不能一直是全力刷吧？毕竟磁盘能力不能只用来刷脏页，还需要服务用户请求。所以接下来，我们就一起看看InnoDB怎么控制引擎按照“全力”的百分比来刷脏页。</p><blockquote><p>InnoDB的刷盘速度就是要参考这两个因素：一个是<strong>脏页比例</strong>，一个是<strong>redo log写盘速度</strong>。</p></blockquote><h3 id="脏页比例"><a href="#脏页比例" class="headerlink" title="脏页比例"></a>脏页比例</h3><p>参数<strong>innodb_max_dirty_pages_pct</strong>是**<code>脏页比例上限</code><strong>，默认值是</strong>75%<strong>。InnoDB会根据当前的</strong><code>脏页比例</code>（假设为M）**，算出一个范围在0到100之间的数字，计算这个数字的伪代码类似这样：(<strong>我自己测试mysql8默认值为90%</strong>)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">F1(M)</span><br><span class="line">&#123;</span><br><span class="line">  if M&gt;=innodb_max_dirty_pages_pct then</span><br><span class="line">      return 100;</span><br><span class="line">  return 100*M/innodb_max_dirty_pages_pct;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="刷脏页的速度计算"><a href="#刷脏页的速度计算" class="headerlink" title="刷脏页的速度计算"></a>刷脏页的速度计算</h3><p>InnoDB每次写入的日志都有一个序号，当前<strong>写入的序号跟checkpoint对应的序号之间的<code>差值</code>，我们假设为N</strong>。InnoDB会根据这个N算出一个范围在0到100之间的数字，这个计算公式可以记为F2(N)。F2(N)算法比较复杂，你只要知道<strong>N越大，算出来的值越大就好了</strong>。</p><blockquote><p>即checkpoint和write pos差的越远，说明空间不多了，刷的越快</p></blockquote><p>然后，<strong>根据上述算得的F1(M)和F2(N)两个值，取其中较大的值记为R，之后引擎就可以按照innodb_io_capacity定义的能力乘以R%来控制刷脏页的速度。</strong></p><blockquote><p>R &#x3D; max(F1(M), F2(N))</p><p>刷脏页的速度 &#x3D; innodb_io_capacity * R</p></blockquote><p>当前<strong>脏页比例越高</strong>，<strong>redo log越久没merge</strong>，即越久没同步磁盘数据，当前<strong>刷脏页速度越快</strong>，**<font color="red">但都需要定义好主机IO能力innodb_io_capacity这个变量</font>**</p><p>现在你知道了，InnoDB会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。所以，无论是你的查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句，都可能是造成你从业务端感知到MySQL“抖”了一下的原因。</p><p>要尽量避免这种情况，你就要合理地设置innodb_io_capacity的值，并且**平时要多关注脏页比例，不要让它经常接近75%**。</p><p>其中，脏页比例是通过Innodb_buffer_pool_pages_dirty&#x2F;Innodb_buffer_pool_pages_total得到的，具体的命令参考下面的代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = &#x27;Innodb_buffer_pool_pages_dirty&#x27;;</span><br><span class="line">select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = &#x27;Innodb_buffer_pool_pages_total&#x27;;</span><br><span class="line">select @a/@b;</span><br></pre></td></tr></table></figure><blockquote><p>一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。而MySQL中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，<strong>如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉</strong>；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是<strong>对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷</strong>。</p><p>在InnoDB中，<strong>innodb_flush_neighbors</strong> 参数就是用来控制这个行为的，值为1的时候会有上述的“连坐”机制，值为0时表示不找邻居，自己刷自己的。</p><p>找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机IO。机械硬盘的随机IOPS一般只有几百，相同的逻辑操作减少随机IO就意味着系统性能的大幅度提升。</p><p>而如果使用的是SSD这类IOPS比较高的设备的话，我就建议你把innodb_flush_neighbors的值设置成0。因为这时候IOPS往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少SQL语句响应时间。</p><p><strong>在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。</strong></p></blockquote><h1 id="13-讲为什么表数据删掉一半，表文件大小不变"><a href="#13-讲为什么表数据删掉一半，表文件大小不变" class="headerlink" title="13 讲为什么表数据删掉一半，表文件大小不变"></a>13 讲为什么表数据删掉一半，表文件大小不变</h1><p>经常会有同学来问我，我的数据库占用空间太大，我把一个最大的表删掉了一半的数据，怎么表文件的大小还是没变？</p><p>那么今天，我就和你聊聊数据库表的空间回收，看看如何解决这个问题。</p><p>这里，我们还是针对MySQL中应用最广泛的InnoDB引擎展开讨论。一个InnoDB表包含两部分，即：表结构定义和数据。在MySQL 8.0版本以前，表结构是存在以.frm为后缀的文件里。而MySQL 8.0版本，则已经允许把表结构定义放在系统数据表中了。因为表结构定义占用的空间很小，所以我们今天主要讨论的是表数据。</p><p>接下来，我会先和你说明为什么简单地删除表数据达不到表空间回收的效果，然后再和你介绍正确回收空间的方法。</p><h2 id="参数innodb-file-per-table"><a href="#参数innodb-file-per-table" class="headerlink" title="参数innodb_file_per_table"></a>参数innodb_file_per_table</h2><p>表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数innodb_file_per_table控制的：</p><ol><li>这个参数设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；</li><li>这个参数设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中。</li></ol><p>从MySQL 5.6.6版本开始，它的默认值就是ON了。</p><p>我建议你不论使用MySQL的哪个版本，都将这个值设置为ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过drop table命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。</p><p>所以，<strong>将innodb_file_per_table设置为ON，是推荐做法，我们接下来的讨论都是基于这个设置展开的。</strong></p><p>我们在删除整个表的时候，可以使用<strong>drop table命令回收表空间</strong>。但是，我们遇到的更多的删除数据的场景是删除某些行，这时就遇到了我们文章开头的问题：表中的数据被删除了，但是表空间却没有被回收。</p><p>我们要彻底搞明白这个问题的话，就要从数据删除流程说起了。</p><blockquote><p>当innodb_file_per_table为ON时，使用drop table能回收表空间</p></blockquote><p>接下来要看的是使用delete删除数据的情况：</p><h2 id="delete删除数据"><a href="#delete删除数据" class="headerlink" title="delete删除数据"></a>delete删除数据</h2><p>因为<strong>记录和数据页都可以被复用</strong></p><p>所以使用delete删除后，表空间未被回收掉，文件大小没减小</p><blockquote><p>但是，<strong>数据页的复用跟记录的复用是不同的。</strong></p><p>记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4这条记录被删除后，如果插入一个ID是400的行，可以直接复用这个空间。但如果插入的是一个ID是800的行，就不能复用这个位置了。</p><p>而当整个页从B+树里面摘掉以后，可以复用到任何位置。以图1为例，如果将数据页page A上的所有记录删除以后，page A会被标记为可复用。这时候如果要插入一条ID&#x3D;50的记录需要使用新页的时候，page A是可以被复用的。</p></blockquote><p>进一步地，如果我们<strong>用delete命令把整个表的数据删除</strong>呢？结果就是，所有的数据页都会被标记为可复用。但是磁盘上，<strong>文件不会变小</strong>。</p><p>delete命令其实只是把记录的位置，或者数据页标记为了<strong>“可复用”</strong>，但磁盘文件的大小是不会变的。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是<strong>“空洞”</strong>。</p><p>实际上，<strong>不止是删除数据会造成空洞，插入数据也会。</strong></p><p>如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。页分裂会时页的空间利用率降低，造成空洞</p><p><strong>更新索引上的值</strong>，可以理解为删除一个旧的值，再插入一个新值。不难理解，这<strong>也是会造成空洞</strong>的。</p><p>也就是说，经过大量<strong>增删改</strong>的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。</p><blockquote><p>insert、delete、update都会造成空洞</p></blockquote><p>而重建表，就可以达到这样的目的。</p><h2 id="解决方法：重建表"><a href="#解决方法：重建表" class="headerlink" title="解决方法：重建表"></a>解决方法：重建表</h2><p>你可以使用alter table A engine&#x3D;InnoDB命令来重建表</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table A engine=InnoDB</span><br></pre></td></tr></table></figure><p>但是分为两种情况，执行的具体过程不同</p><p>分为<strong>MySQL 5.5版本之前和之后</strong></p><p>在MySQL 5.5版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表B不需要你自己创建，MySQL会自动完成转存数据、交换表名、删除旧表的操作。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230926151135184.png" alt="image-20230926151135184"></p><blockquote><p>MySQL5.5之前，是采用在<strong>server层</strong>创建<strong>临时表</strong>来完成表的重建的</p><p>显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表A的话，就会造成数据丢失。因此，<strong>在整个DDL过程中，表A中不能有更新</strong>。也就是说，<strong>这个DDL不是Online的</strong>。</p></blockquote><p><strong>MySQL 5.6版本开始引入的Online DDL，对这个操作流程做了优化。</strong></p><p>我给你简单描述一下引入了Online DDL之后，重建表的流程：</p><ol><li>建立一个临时文件，扫描表A主键的所有数据页；</li><li>用数据页中表A的记录生成B+树，存储到临时文件中；</li><li>生成临时文件的过程中，将所有对A的操作记录在一个<strong>日志文件（row log）</strong>中，对应的是图中state2的状态；</li><li>临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；</li><li>用临时文件替换表A的数据文件。</li></ol><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230926151320804.png" alt="image-20230926151320804"></p><blockquote><p>MySQL5.6开始，是在<strong>存储引擎</strong>创建<strong>临时文件</strong>完成的，并且由于<strong>日志文件</strong>记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表A做增删改操作。这也就是<strong>Online DDL</strong>名字的来源。</p><p>alter语句在启动的时候需要获取MDL写锁，但是这个写锁在真正拷贝数据之前就<strong>退化成读锁</strong>了。所以可以进行表的更新</p><p>为什么要退化呢？为了实现Online，MDL读锁不会阻塞增删改操作。</p></blockquote><p>需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很<strong>消耗IO和CPU资源</strong>的。因此，如果是线上服务，你要很小心地控制操作时间。如果想要比较安全的操作的话，我推荐你使用GitHub开源的gh-ost来做。</p><blockquote><p>注意：在重建表的时候，<strong>InnoDB不会把整张表占满，每个页留了1&#x2F;16给后续的更新用</strong>。也就是说，其实重建表之后<strong>不是“最”紧凑</strong>的。</p></blockquote><h2 id="Online-和-inplace"><a href="#Online-和-inplace" class="headerlink" title="Online 和 inplace"></a>Online 和 inplace</h2><p>MySQL5.5之前，我们把表A中的数据导出来的存放位置叫作tmp_table。这是一个临时表，是在server层创建的。</p><p>MySQL5.5之后，根据表A重建出来的数据是放在“tmp_file”里的，这个临时文件是InnoDB在内部创建出来的。<strong>整个DDL过程都在InnoDB内部完成</strong>。对于server层来说，没有把数据挪动到临时表，是一个<strong>“原地”操作</strong>，这就是<strong>“inplace”</strong>名称的来源。</p><p>所以，我现在问你，如果你有一个1TB的表，现在磁盘间是1.2TB，能不能做一个inplace的DDL呢？</p><p>答案是不能。因为，tmp_file也是要占用临时空间的。</p><p>我们重建表的这个语句alter table t engine&#x3D;InnoDB，其实隐含的意思是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t engine=innodb,ALGORITHM=inplace;</span><br></pre></td></tr></table></figure><p>跟inplace对应的就是拷贝表的方式了，用法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t engine=innodb,ALGORITHM=copy;</span><br></pre></td></tr></table></figure><p>当你使用ALGORITHM&#x3D;copy的时候，表示的是强制拷贝表，对应的流程就是MySQL5.5之前的操作过程。</p><p>但我这样说你可能会觉得，inplace跟Online是不是就是一个意思？</p><p>其实不是的，只是在重建表这个逻辑中刚好是这样而已。</p><p>比如，如果我要给InnoDB表的一个字段加全文索引或空间索引，写法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t add FULLTEXT(field_name);</span><br></pre></td></tr></table></figure><p>这个过程是inplace的，但会阻塞增删改操作，是非Online的。</p><p>如果说这两个逻辑之间的关系是什么的话，可以概括为：</p><ol><li>DDL过程如果是Online的，就一定是inplace的；</li><li>反过来未必，也就是说inplace的DDL，有可能不是Online的。截止到MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引(SPATIAL index)就属于这种情况。</li></ol><blockquote><p>意思就是：MySQL5.6开始，alter语句除了添加全文索引和空间索引，都支持Online DDL</p><p><strong>不影响增删改，就是 Online；相对 Server层没有新建临时表，就是 inplace</strong></p></blockquote><ul><li>从MySQL 5.6版本开始，alter table t engine &#x3D; InnoDB（也就是recreate）默认的就是上面MySQL5.5之后的流程了；</li><li>analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁；</li><li>optimize table t 等于recreate+analyze。</li></ul><h1 id="14-讲count-这么慢，我该怎么办"><a href="#14-讲count-这么慢，我该怎么办" class="headerlink" title="14 讲count(*)这么慢，我该怎么办"></a>14 讲count(*)这么慢，我该怎么办</h1><p>你会发现随着系统中记录数越来越多，这条语句执行得也会越来越慢。然后你可能就想了，MySQL怎么这么笨啊，记个总数，每次要查的时候直接读出来，不就好了吗。</p><p>那么今天，我们就来聊聊count(*)语句到底是怎样实现的，以及MySQL为什么会这么实现。然后，我会再和你说说，如果应用中有这种频繁变更并需要统计表行数的需求，业务设计上可以怎么做。</p><h2 id="count-的实现方式"><a href="#count-的实现方式" class="headerlink" title="count(*)的实现方式"></a>count(*)的实现方式</h2><p>你首先要明确的是，在不同的MySQL引擎中，count(*)有不同的实现方式。</p><ul><li>MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；</li><li>而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。</li></ul><p>这里需要注意的是，我们在这篇文章里讨论的是没有过滤条件的count(*)，如果加了where 条件的话，MyISAM表也是不能返回得这么快的。</p><p>在前面的文章中，我们一起分析了为什么要使用InnoDB，因为不论是在事务支持、并发能力还是在数据安全方面，InnoDB都优于MyISAM。我猜你的表也一定是用了InnoDB引擎。这就是当你的记录数越来越多的时候，计算一个表的总行数会越来越慢的原因。</p><p>当然，现在这个看上去笨笨的MySQL，在执行<strong>count(*)操作的时候还是做了优化</strong>的。</p><p>你知道的，InnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于count(<em>)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到<strong>最小的那棵树</strong>来遍历。*<em>在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。</em></em></p><p>如果你用过show table status 命令的话，就会发现这个命令的输出结果里面也有一个TABLE_ROWS用于显示这个表当前有多少行，这个命令执行挺快的，那这个TABLE_ROWS能代替count(*)吗？</p><p>你可能还记得在第10篇文章<a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/71173">《 MySQL为什么有时候会选错索引？》</a>中我提到过，索引统计的值是通过采样来估算的。实际上，TABLE_ROWS就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到40%到50%。<strong>所以，show table status命令显示的行数也不能直接使用。</strong></p><p>到这里我们小结一下：</p><ul><li>MyISAM表虽然count(*)很快，但是不支持事务；</li><li>show table status命令虽然返回很快，但是不准确；</li><li>InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题。</li></ul><p>到底应该怎么办呢？你需要<strong>自己找一个地方</strong>，把操作记录表的行数存起来。</p><h2 id="用缓存系统保存计数"><a href="#用缓存系统保存计数" class="headerlink" title="用缓存系统保存计数"></a>用缓存系统保存计数</h2><p>你可以用一个Redis服务来保存这个表的总行数。这个表每被插入一行Redis计数就加1，每被删除一行Redis计数就减1。这种方式下，读和更新操作都很快，但你再想一下这种方式存在什么问题吗？</p><p>没错，缓存系统可能会丢失更新。</p><p>当然了，这还是有解的。比如，Redis异常重启以后，到数据库里面单独执行一次count(*)获取真实的行数，再把这个值写回到Redis里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。</p><p>但实际上，<strong>将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使Redis正常工作，这个值还是逻辑上不精确的。</strong></p><p>你可以设想一下有这么一个页面，要显示操作记录的总数，同时还要显示最近操作的100条记录。那么，这个页面的逻辑就需要先到Redis里面取出计数，再到数据表里面取数据记录。</p><p>我们是这么定义不精确的：</p><ol><li>一种是，查到的100行结果里面有最新插入记录，而Redis的计数里还没加1；</li><li>另一种是，查到的100行结果里没有最新插入的记录，而Redis的计数里已经加了1。</li></ol><p>这两种情况，都是逻辑不一致的。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230926153605478.png" alt="image-20230926153605478"></p><p>或者反过来，也是不精确的</p><p>在并发系统里面，我们是无法精确控制不同线程的执行时刻的，因为存在图中的这种操作序列，所以，我们说即使Redis正常工作，这个计数值还是逻辑上不精确的。</p><h2 id="在数据库保存计数"><a href="#在数据库保存计数" class="headerlink" title="在数据库保存计数"></a>在数据库保存计数</h2><p>根据上面的分析，用缓存系统保存计数有丢失数据和计数不精确的问题。那么，<strong>如果我们把这个计数直接放到数据库里单独的一张计数表C中，又会怎么样呢？</strong></p><p>首先，这解决了崩溃丢失的问题，InnoDB是支持崩溃恢复不丢数据的。</p><p>我们这篇文章要解决的问题，都是由于InnoDB要支持事务，从而导致InnoDB表不能把count(*)直接存起来，然后查询的时候直接返回形成的。</p><p>所谓以子之矛攻子之盾，现在我们就利用<strong>“事务”</strong>这个特性，把问题解决掉。</p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)实战45讲笔记.assets/image-20230926153851388.png" alt="image-20230926153851388" style="zoom:50%"><p>我们来看下现在的执行结果。虽然会话B的读操作仍然是在T3执行的，但是因为这时候更新事务还没有提交，所以计数值加1这个操作对会话B还不可见。</p><p>因此，会话B看到的结果里， 查计数值和“最近100条记录”看到的结果，逻辑上就是一致的。</p><h2 id="不同的count用法"><a href="#不同的count用法" class="headerlink" title="不同的count用法"></a>不同的count用法</h2><p>在前面文章的评论区，有同学留言问到：在select count(?) from t这样的查询语句里面，count(* )、count(主键id)、count(字段)和count(1)等不同用法的性能，有哪些差别。今天谈到了count(*)的性能问题，我就借此机会和你详细说明一下这几种用法的性能差别。</p><p>需要注意的是，下面的讨论还是<strong>基于InnoDB</strong>引擎的。</p><p>这里，首先你要弄清楚count()的语义。count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1，否则不加。最后返回累计值。</p><p>所以，count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。</p><p>至于分析性能差别的时候，你可以记住这么几个原则：</p><ol><li>server层要什么就给什么；</li><li>InnoDB只给必要的值；</li><li>现在的优化器只优化了count(*)的语义为“取行数”，其他“显而易见”的优化并没有做。</li></ol><p>这是什么意思呢？接下来，我们就一个个地来看看。</p><p><strong>对于count(主键id)来说</strong>，InnoDB引擎会遍历整张表，把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。</p><p><strong>对于count(1)来说</strong>，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。</p><p>单看这两个用法的差别的话，你能对比出来，count(1)执行得要比count(主键id)快。因为从引擎返回id会涉及到解析数据行，以及拷贝字段值的操作。</p><p><strong>对于count(字段)来说</strong>：</p><ol><li>如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；</li><li>如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。</li></ol><p>也就是前面的第一条原则，server层要什么字段，InnoDB就返回什么字段。</p><p><strong>但是count(*)是例外</strong>，并不会把全部字段取出来，而是<strong>专门做了优化</strong>，不取值。count(*)肯定不是null，按行累加。会找到<strong>最小的那棵树</strong>遍历</p><p>看到这里，你一定会说，优化器就不能自己判断一下吗，主键id肯定非空啊，为什么不能按照count(*)来处理，多么简单的优化啊。</p><p>当然，MySQL专门针对这个语句进行优化，也不是不可以。但是这种需要专门优化的情况太多了，而且MySQL已经优化过count(*)了，你直接使用这种用法就可以了。</p><p>所以结论是：按照效率排序的话，*<em>count(字段)&lt;count(主键id)&lt;count(1)≈count(</em> )*<em>，所以我建议你，尽量使用count(</em>)。</p><blockquote><p>其实，把计数放在Redis里面，不能够保证计数和MySQL表里的数据精确一致的原因，是<strong>这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。</strong>而把计数值也放在MySQL中，就解决了一致性视图的问题。</p><p>InnoDB引擎支持事务，我们利用好事务的原子性和隔离性，就可以简化在业务开发时的逻辑。这也是InnoDB引擎备受青睐的原因之一。</p></blockquote><h1 id="15-讲答疑文章（一）：日志和索引相关问题"><a href="#15-讲答疑文章（一）：日志和索引相关问题" class="headerlink" title="15 讲答疑文章（一）：日志和索引相关问题"></a>15 讲答疑文章（一）：日志和索引相关问题</h1><h2 id="两阶段提交不同异常重启的现象"><a href="#两阶段提交不同异常重启的现象" class="headerlink" title="两阶段提交不同异常重启的现象"></a>两阶段提交不同异常重启的现象</h2><p>《02》</p><p><strong>在两阶段提交的不同时刻，MySQL异常重启会出现什么现象。</strong></p><p>如果在图中时刻A的地方，也就是写入redo log 处于prepare阶段之后、写binlog之前，发生了崩溃（crash），由于此时binlog还没写，redo log也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog还没写，所以也不会传到备库。到这里，大家都可以理解。</p><p>大家出现问题的地方，主要集中在时刻B，也就是binlog写完，redo log还没commit前发生crash，那崩溃恢复的时候MySQL会怎么处理？</p><p>我们先来看一下崩溃恢复时的判断规则。</p><ol><li>如果redo log里面的事务是完整的，也就是已经有了commit标识，则直接提交；</li><li>如果redo log里面的事务只有完整的prepare，则判断对应的事务binlog是否存在并完整：<br>a. 如果是，则提交事务；<br>b. 否则，回滚事务。</li></ol><h4 id="追问1：MySQL怎么知道binlog是完整的"><a href="#追问1：MySQL怎么知道binlog是完整的" class="headerlink" title="追问1：MySQL怎么知道binlog是完整的?"></a>追问1：MySQL怎么知道binlog是完整的?</h4><p>回答：一个事务的binlog是有完整格式的：</p><ul><li>statement格式的binlog，最后会有<strong>COMMIT</strong>；</li><li>row格式的binlog，最后会有一个<strong>XID event</strong>。</li></ul><p>另外，在MySQL 5.6.2版本以后，还引入了binlog-checksum参数，用来验证binlog内容的正确性。对于binlog日志由于磁盘原因，可能会在日志中间出错的情况，MySQL可以通过校验checksum的结果来发现。所以，MySQL还是有办法验证事务binlog的完整性的。</p><h4 id="追问2：redo-log-和-binlog是怎么关联起来的"><a href="#追问2：redo-log-和-binlog是怎么关联起来的" class="headerlink" title="追问2：redo log 和 binlog是怎么关联起来的?"></a>追问2：redo log 和 binlog是怎么关联起来的?</h4><p>回答：它们有一个共同的数据字段，叫XID。崩溃恢复的时候，会按顺序扫描redo log：</p><ul><li>如果碰到既有prepare、又有commit的redo log，就直接提交；</li><li>如果碰到只有parepare、而没有commit的redo log，就<strong>拿着XID去binlog找对应的事务</strong>。</li></ul><h4 id="追问3：处于prepare阶段的redo-log加上完整binlog，重启就能恢复，MySQL为什么要这么设计"><a href="#追问3：处于prepare阶段的redo-log加上完整binlog，重启就能恢复，MySQL为什么要这么设计" class="headerlink" title="追问3：处于prepare阶段的redo log加上完整binlog，重启就能恢复，MySQL为什么要这么设计?"></a>追问3：处于prepare阶段的redo log加上完整binlog，重启就能恢复，MySQL为什么要这么设计?</h4><p>回答：其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。在时刻B，也就是binlog写完以后MySQL发生崩溃，这时候binlog已经写入了，之后就会被从库（或者用这个binlog恢复出来的库）使用。</p><p>所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。</p><h4 id="追问4：如果这样的话，为什么还要两阶段提交呢？干脆先redo-log写完，再写binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？"><a href="#追问4：如果这样的话，为什么还要两阶段提交呢？干脆先redo-log写完，再写binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？" class="headerlink" title="追问4：如果这样的话，为什么还要两阶段提交呢？干脆先redo log写完，再写binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？"></a>追问4：如果这样的话，为什么还要两阶段提交呢？干脆先redo log写完，再写binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？</h4><p>回答：其实，两阶段提交是经典的分布式系统问题，并不是MySQL独有的。</p><p>如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。</p><p>对于InnoDB引擎来说，如果redo log提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果redo log直接提交，然后binlog写入的时候失败，InnoDB又回滚不了，数据和binlog日志又不一致了。</p><p>两阶段提交就是为了给所有人一个机会，当每个人都说“我ok”的时候，再一起提交。</p><h4 id="追问5：不引入两个日志，也就没有两阶段提交的必要了。只用binlog来支持崩溃恢复，又能支持归档，不就可以了？"><a href="#追问5：不引入两个日志，也就没有两阶段提交的必要了。只用binlog来支持崩溃恢复，又能支持归档，不就可以了？" class="headerlink" title="追问5：不引入两个日志，也就没有两阶段提交的必要了。只用binlog来支持崩溃恢复，又能支持归档，不就可以了？"></a>追问5：不引入两个日志，也就没有两阶段提交的必要了。只用binlog来支持崩溃恢复，又能支持归档，不就可以了？</h4><p>回答：这位同学的意思是，只保留binlog，然后可以把提交流程改成这样：… -&gt; “数据更新到内存” -&gt; “写 binlog” -&gt; “提交事务”，是不是也可以提供崩溃恢复的能力？</p><p>答案是不可以。</p><p>如果说<strong>历史原因</strong>的话，那就是InnoDB并不是MySQL的原生存储引擎。MySQL的原生引擎是MyISAM，设计之初就有没有支持崩溃恢复。</p><p>InnoDB在作为MySQL的插件加入MySQL引擎家族之前，就已经是一个提供了崩溃恢复和事务支持的引擎了。</p><p>InnoDB接入了MySQL后，发现既然binlog没有崩溃恢复的能力，那就用InnoDB原有的redo log好了。</p><p>而如果说<strong>实现上的原因</strong>的话，就有很多了。就按照问题中说的，只用binlog来实现崩溃恢复的流程，我画了一张示意图，这里就没有redo log了。</p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)实战45讲笔记.assets/image-20230927100447599.png" alt="image-20230927100447599" style="zoom:50%"><p>这样的流程下，binlog还是不能支持崩溃恢复的。我说一个不支持的点吧：binlog没有能力恢复“数据页”。</p><p>如果在图中标的位置，也就是binlog2写完了，但是整个事务还没有commit的时候，MySQL发生了crash。</p><p>重启后，引擎内部事务2会回滚，然后应用binlog2可以补回来；但是对于事务1来说，系统已经认为提交完成了，不会再应用一次binlog1。</p><p>但是，InnoDB引擎使用的是WAL技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。</p><p>也就是说在图中这个位置发生崩溃的话，事务1也是可能丢失了的，而且是数据页级的丢失。此时，binlog里面并没有记录数据页的更新细节，是补不回来的。</p><p>你如果要说，那我优化一下binlog的内容，让它来记录数据页的更改可以吗？但，这其实就是又做了一个redo log出来。</p><p>所以，至少现在的binlog能力，还不能支持崩溃恢复。</p><h4 id="追问6：那能不能反过来，只用redo-log，不要binlog？"><a href="#追问6：那能不能反过来，只用redo-log，不要binlog？" class="headerlink" title="追问6：那能不能反过来，只用redo log，不要binlog？"></a>追问6：那能不能反过来，只用redo log，不要binlog？</h4><p>回答：如果只从崩溃恢复的角度来讲是可以的。你可以把binlog关掉，这样就没有两阶段提交了，但系统依然是crash-safe的。</p><p>但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog都是开着的。因为binlog有着redo log无法替代的功能。</p><p>一个是归档。redo log是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log也就起不到归档的作用。</p><p>一个就是MySQL系统依赖于binlog。binlog作为MySQL一开始就有的功能，被用在了很多地方。其中，MySQL系统高可用的基础，就是binlog复制。</p><p>还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费MySQL的binlog来更新自己的数据。关掉binlog的话，这些下游系统就没法输入了。</p><p>总之，由于现在包括MySQL高可用在内的很多系统机制都依赖于binlog，所以“鸠占鹊巢”redo log还做不到。你看，发展生态是多么重要。</p><h4 id="追问7：redo-log一般设置多大？"><a href="#追问7：redo-log一般设置多大？" class="headerlink" title="追问7：redo log一般设置多大？"></a>追问7：redo log一般设置多大？</h4><p>回答：redo log太小的话，会导致很快就被写满，然后不得不强行刷redo log，这样WAL机制的能力就发挥不出来了。</p><p>所以，如果是现在常见的几个TB的磁盘的话，就不要太小气了，直接将redo log设置为4个文件、每个文件1GB吧。</p><h4 id="追问8：正常运行中的实例，数据写入后的最终落盘，是从redo-log更新过来的还是从buffer-pool更新过来的呢？"><a href="#追问8：正常运行中的实例，数据写入后的最终落盘，是从redo-log更新过来的还是从buffer-pool更新过来的呢？" class="headerlink" title="追问8：正常运行中的实例，数据写入后的最终落盘，是从redo log更新过来的还是从buffer pool更新过来的呢？"></a>追问8：正常运行中的实例，数据写入后的最终落盘，是从redo log更新过来的还是从buffer pool更新过来的呢？</h4><p>回答：这个问题其实问得非常好。这里涉及到了，“redo log里面到底是什么”的问题。</p><p>实际上，redo log并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由redo log更新过去”的情况。</p><ol><li>如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与redo log毫无关系。</li><li>在崩溃恢复场景中，InnoDB如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让redo log更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。</li></ol><h4 id="追问9：redo-log-buffer是什么？是先修改内存，还是先写redo-log文件？"><a href="#追问9：redo-log-buffer是什么？是先修改内存，还是先写redo-log文件？" class="headerlink" title="追问9：redo log buffer是什么？是先修改内存，还是先写redo log文件？"></a>追问9：redo log buffer是什么？是先修改内存，还是先写redo log文件？</h4><p>回答：这两个问题可以一起回答。</p><p>在一个事务的更新过程中，日志是要写多次的。比如下面这个事务：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">begin;</span><br><span class="line">insert into t1 ...</span><br><span class="line">insert into t2 ...</span><br><span class="line">commit;</span><br></pre></td></tr></table></figure><p>这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没commit的时候就直接写到redo log文件里。</p><p>所以，redo log buffer就是一块内存，用来先存redo日志的。也就是说，在执行第一个insert的时候，数据的内存被修改了，redo log buffer也写入了日志。</p><p>但是，真正把日志写到redo log文件（文件名是 ib_logfile+数字），是在执行commit语句的时候做的。</p><p>（这里说的是事务执行过程中不会“主动去刷盘”，以减少不必要的IO消耗。但是可能会出现“被动写入磁盘”，比如内存不够、其他事务提交等情况。这个问题我们会在后面第22篇文章《MySQL有哪些“饮鸩止渴”的提高性能的方法？》中再详细展开）。</p><p>单独执行一个更新语句的时候，InnoDB会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。</p><h2 id="修改一样的数据MySQL会怎样运行"><a href="#修改一样的数据MySQL会怎样运行" class="headerlink" title="修改一样的数据MySQL会怎样运行"></a>修改一样的数据MySQL会怎样运行</h2><p>这时候，表t里有唯一的一行数据(1,2)。假设，我现在要执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update t set a=2 where id=1;</span><br></pre></td></tr></table></figure><p>你会看到这样的结果：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/367b3f299b94353f32f75ea825391170.png" alt="img"><br>结果显示，匹配(rows matched)了一行，修改(Changed)了0行。</p><p>仅从现象上看，MySQL内部在处理这个命令的时候，可以有以下三种选择：</p><ol><li>更新都是先读后写的，MySQL读出数据，发现a的值本来就是2，不更新，直接返回，执行结束；</li><li>MySQL调用了InnoDB引擎提供的“修改为(1,2)”这个接口，但是引擎发现值与原来相同，不更新，直接返回；</li><li>InnoDB认真执行了“把这个值修改成(1,2)”这个操作，该加锁的加锁，该更新的更新。</li></ol><blockquote><p>MySQL采取的措施是第三条</p></blockquote><h1 id="16-讲“orderby”是怎么工作的"><a href="#16-讲“orderby”是怎么工作的" class="headerlink" title="16 讲“orderby”是怎么工作的"></a>16 讲“orderby”是怎么工作的</h1><p>在你开发应用的时候，一定会经常碰到需要根据指定的字段排序来显示结果的需求。还是以我们前面举例用过的市民表为例，假设你要查询城市是“杭州”的所有人名字，并且按照姓名排序返回前1000个人的姓名、年龄。</p><p>假设这个表的部分定义是这样的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `city` varchar(16) NOT NULL,</span><br><span class="line">  `name` varchar(16) NOT NULL,</span><br><span class="line">  `age` int(11) NOT NULL,</span><br><span class="line">  `addr` varchar(128) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  KEY `city` (`city`)</span><br><span class="line">) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure><p>这时，你的SQL语句可以这么写：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select city,name,age from t where city=&#x27;杭州&#x27; order by name limit 1000  ;</span><br></pre></td></tr></table></figure><p>这个语句看上去逻辑很清晰，但是你了解它的执行流程吗？今天，我就和你聊聊这个语句是怎么执行的，以及有什么参数会影响执行的行为。</p><h2 id="filesort归并排序"><a href="#filesort归并排序" class="headerlink" title="filesort归并排序"></a>filesort归并排序</h2><p>如果name字段不能使用索引排序，那么将会使用filesort</p><p>前面我们介绍过索引，所以你现在就很清楚了，为避免全表扫描，我们需要在city字段加上索引。</p><p>在city字段上创建索引之后，我们用explain命令来看看这个语句的执行情况。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/826579b63225def812330ef6c344a303.png" alt="img"></p><p>​ 图1 使用explain命令查看语句的执行情况</p><p>Extra这个字段中的“Using filesort”表示的就是需要排序，MySQL会给每个线程分配一块内存用于排序，称为sort_buffer。</p><p>为了说明这个SQL查询语句的执行过程，我们先来看一下city这个索引的示意图。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230927101107961.png" alt="image-20230927101107961"></p><p>​ 图2 city字段的索引示意图</p><p>从图中可以看到，满足city&#x3D;’杭州’条件的行，是从ID_X到ID_(X+N)的这些记录。</p><h3 id="全字段排序"><a href="#全字段排序" class="headerlink" title="全字段排序"></a>全字段排序</h3><p>当<strong>sort_buffer_size &gt; 要排序的数据</strong>时，</p><p>这个语句执行流程如下所示 ：</p><ol><li>初始化sort_buffer，确定放入name、city、age这三个字段；</li><li>从索引city找到第一个满足city&#x3D;’杭州’条件的主键id，也就是图中的ID_X；</li><li>到主键id索引取出整行，取name、city、age三个字段的值，存入sort_buffer中；</li><li>从索引city取下一个记录的主键id；</li><li>重复步骤3、4直到city的值不满足查询条件为止，对应的主键id也就是图中的ID_Y；</li><li>对sort_buffer中的数据按照字段name做快速排序；</li><li>按照排序结果取前1000行返回给客户端。</li></ol><p>我们暂且把这个排序过程，称为<strong>全字段排序</strong>，执行流程的示意图如下所示，下一篇文章中我们还会用到这个排序。</p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)实战45讲笔记.assets/6c821828cddf46670f9d56e126e3e772.jpg" alt="img" style="zoom:50%"><p>​ 图3 全字段排序</p><p>图中“按name排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取<strong>决于排序所需的内存和参数sort_buffer_size</strong>。</p><p>sort_buffer_size，就是MySQL为排序开辟的内存（sort_buffer）的大小。<strong>如果要排序的数据量小于sort_buffer_size，排序就在内存中完成</strong>。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。</p><blockquote><p>你可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">/* 打开optimizer_trace，只对本线程有效 */</span><br><span class="line">SET optimizer_trace=&#x27;enabled=on&#x27;; </span><br><span class="line"></span><br><span class="line">/* @a保存Innodb_rows_read的初始值 */</span><br><span class="line">select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = &#x27;Innodb_rows_read&#x27;;</span><br><span class="line"></span><br><span class="line">/* 执行语句 */</span><br><span class="line">select city, name,age from t where city=&#x27;杭州&#x27; order by name limit 1000; </span><br><span class="line"></span><br><span class="line">/* 查看 OPTIMIZER_TRACE 输出 */</span><br><span class="line">SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G</span><br><span class="line"></span><br><span class="line">/* @b保存Innodb_rows_read的当前值 */</span><br><span class="line">select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = &#x27;Innodb_rows_read&#x27;;</span><br><span class="line"></span><br><span class="line">/* 计算Innodb_rows_read差值 */</span><br><span class="line">select @b-@a;</span><br></pre></td></tr></table></figure><p>这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files中看到是否使用了临时文件。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/89baf99cdeefe90a22370e1d6f5e6495.png" alt="img"></p><p>​ 图4 全排序的OPTIMIZER_TRACE部分结果</p><ul><li>number_of_tmp_files：排序过程中使用的临时文件数<ul><li>内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，<strong>MySQL将需要排序的数据分成12份，每一份单独排序后存在这些临时文件中。然后把这12个有序文件再合并成一个有序的大文件。</strong></li><li>如果sort_buffer_size超过了需要排序的数据量的大小，number_of_tmp_files就是0，表示排序可以直接在内存中完成</li></ul></li><li>examined_rows&#x3D;4000，表示参与排序的行数是4000行。</li><li>sort_mode 里面的packed_additional_fields的意思是，<strong>全字段排序</strong>，并在排序过程对字符串做了“紧凑”处理。即使name字段的定义是varchar(16)，在排序过程中还是要按照实际长度来分配空间的。</li><li>最后一个查询语句select @b-@a 的返回结果是4000，表示整个执行过程只扫描了4000行。<ul><li>这里需要注意的是，为了避免对结论造成干扰，我把internal_tmp_disk_storage_engine设置成MyISAM。否则，select @b-@a的结果会显示为4001。这是因为查询OPTIMIZER_TRACE这个表时，需要用到临时表，而internal_tmp_disk_storage_engine的默认值是InnoDB。如果使用的是InnoDB引擎的话，把数据从临时表取出来的时候，会让Innodb_rows_read的值加1。</li></ul></li></ul></blockquote><h3 id="rowid排序"><a href="#rowid排序" class="headerlink" title="rowid排序"></a>rowid排序</h3><p>在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在sort_buffer和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么sort_buffer里面要放的字段数太多，这样内存里能够同时放下的行数很少，<strong>要分成很多个临时文件，排序的性能会很差</strong>。</p><p>所以<strong>如果单行很大，这个方法效率不够好</strong>。</p><p>接下来，我来修改一个参数，让MySQL采用另外一种算法。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET max_length_for_sort_data = 16;</span><br></pre></td></tr></table></figure><p>max_length_for_sort_data，是MySQL中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL就认为单行太大，要换一个算法。</p><p>city、name、age 这三个字段的定义总长度是36，我把max_length_for_sort_data设置为16，我们再来看看计算过程有什么改变。</p><p>新的算法放入sort_buffer的字段，只有要排序的列（即name字段）和主键id。</p><p>但这时，排序的结果就因为少了city和age字段的值，不能直接返回了，整个执行流程就变成如下所示的样子：</p><ol><li>初始化sort_buffer，确定放入两个字段，即name和id；</li><li>从索引city找到第一个满足city&#x3D;’杭州’条件的主键id，也就是图中的ID_X；</li><li>到主键id索引取出整行，取name、id这两个字段，存入sort_buffer中；</li><li>从索引city取下一个记录的主键id；</li><li>重复步骤3、4直到不满足city&#x3D;’杭州’条件为止，也就是图中的ID_Y；</li><li>对sort_buffer中的数据按照字段name进行排序；</li><li>遍历排序结果，取前1000行，并<strong>按照id的值回到原表</strong>中取出city、name和age三个字段返回给客户端。</li></ol><p>这个执行流程的示意图如下，我把它称为rowid排序。</p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)实战45讲笔记.assets/dc92b67721171206a302eb679c83e86d.jpg" alt="img" style="zoom:50%"><p>​ 图5 rowid排序</p><p>对比图3的全字段排序流程图你会发现，<strong>rowid排序多访问了一次表t的主键索引</strong>，就是步骤7。</p><p>需要说明的是，最后的“结果集”是一个逻辑概念，实际上MySQL服务端从排序后的sort_buffer中依次取出id，然后到原表查到city、name和age这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。</p><p>根据这个说明过程和图示，你可以想一下，这个时候执行select @b-@a，结果会是多少呢？</p><p>现在，我们就来看看结果有什么不同。</p><p>首先，图中的examined_rows的值还是4000，表示用于排序的数据是4000行。但是select @b-@a这个语句的值变成5000了。</p><p>因为这时候除了排序过程外，在排序完成后，还要根据id去原表取值。由于语句是limit 1000，因此会多读1000行。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/27f164804d1a4689718291be5d10f89b.png" alt="img"></p><p>​ 图6 rowid排序的OPTIMIZER_TRACE部分输出</p><p>从OPTIMIZER_TRACE的结果中，你还能看到另外两个信息也变了。</p><ul><li>sort_mode变成了&lt;sort_key, **rowid**&gt;，表示参与排序的只有name和id这两个字段。</li><li>number_of_tmp_files变成10了，是因为这时候参与排序的行数虽然仍然是4000行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变少了。</li></ul><h3 id="全字段排序-VS-rowid排序"><a href="#全字段排序-VS-rowid排序" class="headerlink" title="全字段排序 VS rowid排序"></a>全字段排序 VS rowid排序</h3><ul><li>如果MySQL实在是担心排序内存太小，会影响排序效率，才会采用rowid排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。</li><li>如果MySQL认为内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。</li></ul><p>这也就体现了MySQL的一个设计思想：<strong>如果内存够，就要多利用内存，尽量减少磁盘访问。</strong></p><p><strong>对于InnoDB表来说，rowid排序会要求回表多造成磁盘读，因此不会被优先选择。</strong></p><blockquote><p>全字段排序<br>1.通过索引将所需的字段全部读取到sort_buffer中<br>2.按照排序字段进行排序<br>3.将结果集返回给客户端</p><p>缺点：<br>1.造成sort_buffer中存放不下很多数据，因为除了排序字段还存放其他字段，对sort_buffer的利用效率不高<br>2.当所需排序数据量很大时，会有很多的临时文件，排序性能也会很差</p><p>优点：MySQL认为内存足够大时会优先选择全字段排序，因为这种方式比rowid 排序避免了一次回表操作</p><p>rowid排序<br>1.通过控制排序的行数据的长度来让sort_buffer中尽可能多的存放数据，max_length_for_sort_data<br>2.只将需要排序的字段和主键读取到sort_buffer中，并按照排序字段进行排序<br>3.按照排序后的顺序，取id进行回表取出想要获取的数据<br>4.将结果集返回给客户端</p><p>优点：更好的利用内存的sort_buffer进行排序操作，尽量减少对磁盘的访问</p><p>缺点：回表的操作是随机IO，会造成大量的随机读，不一定就比全字段排序减少对磁盘的访问</p></blockquote><h2 id="索引排序"><a href="#索引排序" class="headerlink" title="索引排序"></a>索引排序</h2><p>其实，并不是所有的order by语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL之所以需要生成临时表，并且在临时表上做排序操作，<strong>其原因是原来的数据都是无序的。</strong></p><p>你可以设想下，如果能够保证从city这个索引上取出来的行，天然就是按照name递增排序的话，是不是就可以不用再排序了呢？</p><p>确实是这样的。</p><p>所以，我们可以在这个市民表上创建一个city和name的联合索引，对应的SQL语句是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t add index city_user(city, name);</span><br></pre></td></tr></table></figure><p>作为与city索引的对比，我们来看看这个索引的示意图。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230927102414680.png" alt="image-20230927102414680"></p><p>​ 图7 city和name联合索引示意图</p><p>在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足city&#x3D;’杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要city的值是杭州，name的值就一定是有序的。</p><p>这样整个查询过程的流程就变成了：</p><ol><li>从索引(city,name)找到第一个满足city&#x3D;’杭州’条件的主键id；</li><li>到主键id索引取出整行，取name、city、age三个字段的值，作为结果集的一部分直接返回；</li><li>从索引(city,name)取下一个记录主键id；</li><li>重复步骤2、3，直到查到第1000条记录，或者是不满足city&#x3D;’杭州’条件时循环结束。</li></ol><p>可以看到，这个查询过程不需要临时表，也不需要排序。接下来，我们用explain的结果来印证一下。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/fc53de303811ba3c46d344595743358a.png" alt="img"></p><p>​ 图9 引入(city,name)联合索引后，查询语句的执行计划</p><p>从图中可以看到，Extra字段中没有Using filesort了，也就是不需要排序了。而且由于(city,name)这个联合索引本身有序，所以这个查询也不用把4000行全都读一遍，只要找到满足条件的前1000条记录就可以退出了。也就</p><p>是说，在我们这个例子里，只需要扫描1000次。</p><p>这里我们可以再稍微复习一下。<strong>覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。</strong></p><p>按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。</p><p>针对这个查询，我们可以创建一个city、name和age的联合索引，对应的SQL语句就是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table t add index city_user_age(city, name, age);</span><br></pre></td></tr></table></figure><p>这时，对于city字段的值相同的行来说，还是按照name字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：</p><ol><li>从索引(city,name,age)找到第一个满足city&#x3D;’杭州’条件的记录，取出其中的city、name和age这三个字段的值，作为结果集的一部分直接返回；</li><li>从索引(city,name,age)取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；</li><li>重复执行步骤2，直到查到第1000条记录，或者是不满足city&#x3D;’杭州’条件时循环结束。</li></ol><p>然后，我们再来看看explain的结果。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/9e40b7b8f0e3f81126a9171cc22e3423.png" alt="img"></p><p>​ 图11 引入(city,name,age)联合索引后，查询语句的执行计划</p><p>可以看到，Extra字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。</p><p>当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>假设你的表里面已经有了city_name(city, name)这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前100条记录。如果SQL查询语句是这么写的 ：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t where city in (&#x27;杭州&#x27;,&quot;苏州&quot;) order by name limit 100;</span><br></pre></td></tr></table></figure><p>那么，这个语句执行的时候会有排序过程吗，为什么？</p><blockquote><p>虽然有(city,name)联合索引，对于单个city内部，name是递增的。但是由于这条SQL语句不是要单独地查一个city的值，而是同时查了”杭州”和” 苏州 “两个城市，因此所有满足条件的name就不是递增的了。也就是说，<strong>这条SQL语句需要排序。</strong></p><p>那怎么避免排序呢？</p><p>这里，我们要用到(city,name)联合索引的特性，把这一条语句拆成两条语句，执行流程如下：</p><ol><li>执行select * from t where city&#x3D;“杭州” order by name limit 100; 这个语句是不需要排序的，客户端用一个长度为100的内存数组A保存结果。</li><li>执行select * from t where city&#x3D;“苏州” order by name limit 100; 用相同的方法，假设结果被存进了内存数组B。</li><li>现在A和B是两个有序数组，然后你可以用归并排序的思想，得到name最小的前100值，就是我们需要的结果了。</li></ol></blockquote><h1 id="17-orderby-2-如何正确地显示随机消息"><a href="#17-orderby-2-如何正确地显示随机消息" class="headerlink" title="17 orderby 2 如何正确地显示随机消息"></a>17 orderby 2 如何正确地显示随机消息</h1><p>这个英语学习App首页有一个随机显示单词的功能，也就是根据每个用户的级别有一个单词表，然后这个用户每次访问首页的时候，都会随机滚动显示三个单词。他们发现随着单词表变大，选单词这个逻辑变得越来越慢，甚至影响到了首页的打开速度。</p><p>现在，如果让你来设计这个SQL语句，你会怎么写呢？</p><p>为了便于理解，我对这个例子进行了简化：去掉每个级别的用户都有一个对应的单词表这个逻辑，直接就是从一个单词表中随机选出三个单词。这个表的建表语句和初始数据的命令如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TABLE `words` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `word` varchar(64) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure><p>为了便于量化说明，我在这个表里面插入了10000行记录。接下来，我们就一起看看要随机选择3个单词，有什么方法实现，存在什么问题以及如何改进。</p><h2 id="内存临时表"><a href="#内存临时表" class="headerlink" title="内存临时表"></a>内存临时表</h2><p>首先，你会想到用**order by rand()**来实现这个逻辑。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select word from words order by rand() limit 3;</span><br></pre></td></tr></table></figure><p>这个语句的意思很直白，随机排序取前3个。虽然这个SQL语句写法很简单，但执行流程却有点复杂的。</p><p>我们先用explain命令来看看这个语句的执行情况。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/59a4fb0165b7ce1184e41f2d061ce350.png" alt="img"></p><p>​ 图1 使用explain命令查看语句的执行情况</p><p>Extra字段显示<strong>Using temporary</strong>，表示的是需要使用临时表；<strong>Using filesort</strong>，表示的是需要执行排序操作。</p><p>因此这个Extra的意思就是，需要临时表，并且需要在临时表上排序。</p><p>然后，我再问你一个问题，你觉得对于临时内存表的排序来说，它会选择哪一种算法呢？回顾一下上一篇文章的一个结论：<strong>对于InnoDB表来说</strong>，执行全字段排序会减少磁盘访问，因此会被优先选择。</p><p>我强调了“InnoDB表”，你肯定想到了，<strong>对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘</strong>。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越少越好了，所以，MySQL这时就会选择rowid排序。</p><p>理解了这个算法选择的逻辑，我们再来看看语句的执行流程。同时，通过今天的这个例子，我们来尝试分析一下语句的扫描行数。</p><p>这条语句的执行流程是这样的：</p><ol><li>创建一个临时表。这个临时表使用的是memory引擎，表里有两个字段，第一个字段是double类型，为了后面描述方便，记为字段R，第二个字段是varchar(64)类型，记为字段W。并且，这个表没有建索引。</li><li>从words表中，按主键顺序取出所有的word值。对于每一个word值，调用rand()函数生成一个大于0小于1的随机小数，并把这个随机小数和word分别存入临时表的R和W字段中，到此，扫描行数是10000。</li><li>现在临时表有10000行数据了，接下来你要在这个没有索引的内存临时表上，按照字段R排序。</li><li>初始化 sort_buffer。sort_buffer中有两个字段，一个是double类型，另一个是整型。</li><li>从内存临时表中一行一行地取出R值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入sort_buffer中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加10000，变成了20000。</li><li>在sort_buffer中根据R的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。</li><li>排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出word值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了20003。</li></ol><p>接下来，我们通过<strong>慢查询日志（slow log）</strong>来验证一下我们分析得到的扫描行数是否正确。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Query_time: 0.900376  Lock_time: 0.000347 Rows_sent: 3 Rows_examined: 20003</span><br><span class="line">SET timestamp=1541402277;</span><br><span class="line">select word from words order by rand() limit 3;</span><br></pre></td></tr></table></figure><p>其中，Rows_examined：20003就表示这个语句执行过程中扫描了20003行，也就验证了我们分析得出的结论。</p><p>这里插一句题外话，在平时学习概念的过程中，你可以经常这样做，先通过原理分析算出扫描行数，然后再通过查看慢查询日志，来验证自己的结论。我自己就是经常这么做，这个过程很有趣，分析对了开心，分析错了但是弄清楚了也很开心。</p><p>现在，我来把完整的排序执行流程图画出来。</p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)实战45讲笔记.assets/image-20230928180111638.png" alt="image-20230928180111638" style="zoom:50%"><p>​ 图4 随机排序完整流程图1</p><p>图中的pos就是位置信息，你可能会觉得奇怪，这里的“位置信息”是个什么概念？在上一篇文章中，我们对InnoDB表排序的时候，明明用的还是ID字段。</p><p>这时候，我们就要回到一个基本概念：<strong>MySQL的表是用什么方法来定位“一行数据”的。</strong></p><p>在前面<a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/69236">第4</a>和<a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/69636">第5</a>篇介绍索引的文章中，有几位同学问到，如果把一个InnoDB表的主键删掉，是不是就没有主键，就没办法回表了？</p><p>其实不是的。如果你创建的表没有主键，或者把一个表的主键删掉了，那么InnoDB会自己生成一个长度为6字节的rowid来作为主键。</p><p>这也就是排序模式里面，rowid名字的来历。实际上它表示的是：每个引擎用来唯一标识数据行的信息。</p><ul><li>对于有主键的InnoDB表来说，这个rowid就是主键ID；</li><li>对于没有主键的InnoDB表来说，这个rowid就是由系统生成的；</li><li>MEMORY引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个rowid其实就是数组的下标。</li></ul><p>到这里，我来稍微小结一下：<strong>order by rand()使用了内存临时表，内存临时表排序的时候使用了rowid排序方法。</strong></p><h2 id="磁盘临时表InnoDB"><a href="#磁盘临时表InnoDB" class="headerlink" title="磁盘临时表InnoDB"></a>磁盘临时表InnoDB</h2><blockquote><p>磁盘临时表是上一节中归并排序的两种方式，</p><p>而内存临时表内存（tmp_table_size）不足时才会别为磁盘临时表，</p><ul><li>使用内存临时表会优先选择rowid排序，因为在内存中回表消耗不大，不用读磁盘</li></ul><p>磁盘临时表是<strong>InnoDB表</strong>，有三种排序方式，一般情况下速度从快到满依次是：</p><ol><li>优先队列排序	limit数据量大小 &lt; sort_buffer_size，在内存中构造大顶堆完成</li><li>全字段排序 sort_buffer_size &gt; 数据量大小，不使用磁盘文件</li><li>rowid排序 sort_buffer_size &lt; 数据量大小，使用磁盘文件，需要回表读磁盘，最慢</li></ol></blockquote><p>那么，是不是所有的临时表都是内存表呢？</p><p>其实不是的。<strong>tmp_table_size</strong>这个配置限制了内存临时表的大小，默认值是<strong>16M</strong>。如果临时表大小超过了tmp_table_size，那么内存临时表就会转成磁盘临时表。</p><p><strong>磁盘临时表使用的引擎默认是InnoDB</strong>，是由参数internal_tmp_disk_storage_engine控制的。</p><p>当使用磁盘临时表的时候，对应的就是一个没有显式索引的InnoDB表的排序过程。</p><p>为了复现这个过程，我把tmp_table_size设置成1024，把sort_buffer_size设置成 32768, 把 max_length_for_sort_data 设置成16。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">set tmp_table_size=1024;</span><br><span class="line">set sort_buffer_size=32768;</span><br><span class="line">set max_length_for_sort_data=16;</span><br><span class="line">/* 打开 optimizer_trace，只对本线程有效 */</span><br><span class="line">SET optimizer_trace=&#x27;enabled=on&#x27;; </span><br><span class="line"></span><br><span class="line">/* 执行语句 */</span><br><span class="line">select word from words order by rand() limit 3;</span><br><span class="line"></span><br><span class="line">/* 查看 OPTIMIZER_TRACE 输出 */</span><br><span class="line">SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G</span><br></pre></td></tr></table></figure><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/78d2db9a4fdba81feadccf6e878b4aab.png" alt="img"></p><p>​ 图5 OPTIMIZER_TRACE部分结果</p><p>然后，我们来看一下这次OPTIMIZER_TRACE的结果。</p><p>因为将max_length_for_sort_data设置成16，小于word字段的长度定义，所以我们看到sort_mode里面显示的是rowid排序，这个是符合预期的，参与排序的是随机值R字段和rowid字段组成的行。</p><h3 id="优先队列排序"><a href="#优先队列排序" class="headerlink" title="优先队列排序"></a>优先队列排序</h3><p>这时候你可能心算了一下，发现不对。R字段存放的随机值就8个字节，rowid是6个字节（至于为什么是6字节，就留给你课后思考吧），数据总行数是10000，这样算出来就有140000字节，<strong>超过了sort_buffer_size 定义的 32768字节</strong>了。但是，number_of_tmp_files的值居然是0，难道不需要用临时文件吗？</p><p>这个SQL语句的排序确实没有用到临时文件，采用是MySQL 5.6版本引入的一个新的排序算法，即：<strong>优先队列排序算法</strong>。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了优先队列排序算法。</p><p>其实，我们现在的SQL语句，<strong>只需要取R值最小的3个rowid</strong>。但是，如果使用归并排序算法的话，虽然最终也能得到前3个值，但是这个算法结束后，已经将10000行数据都排好序了。</p><p>也就是说，后面的9997行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量。</p><p>而优先队列算法，就可以精确地只得到三个最小值，执行流程如下：</p><ol><li>对于这10000个准备排序的(R,rowid)，先取前三行，构造成一个堆；</li></ol><p>（对数据结构印象模糊的同学，可以先设想成这是一个由三个元素组成的数组）</p><ol><li>取下一个行(R’,rowid’)，跟当前堆里面最大的R比较，如果R’小于R，把这个(R,rowid)从堆中去掉，换成(R’,rowid’)；</li><li>重复第2步，直到第10000个(R’,rowid’)完成比较。</li></ol><p>这里我简单画了一个优先队列排序过程的示意图。</p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)实战45讲笔记.assets/e9c29cb20bf9668deba8981e444f6897.png" alt="img" style="zoom:33%"><p>​ 图6 优先队列排序算法示例</p><p>图6是模拟6个(R,rowid)行，通过优先队列排序找到最小的三个R值的行的过程。整个排序过程中，为了最快地拿到当前堆的最大值，总是保持最大值在堆顶，因此这是一个<strong>最大堆</strong>。</p><p>图5的OPTIMIZER_TRACE结果中，<strong>filesort_priority_queue_optimization这个部分的chosen&#x3D;true</strong>，就表示使用了优先队列排序算法，这个过程不需要临时文件，因此对应的number_of_tmp_files是0。</p><p>这个流程结束后，我们构造的堆里面，就是这个10000行里面R值最小的三行。然后，依次把它们的rowid取出来，去临时表里面拿到word字段，这个过程就跟上一篇文章的rowid排序的过程一样了。</p><p>我们再看一下上面一篇文章的SQL查询语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select city,name,age from t where city=&#x27;杭州&#x27; order by name limit 1000  ;</span><br></pre></td></tr></table></figure><p>你可能会问，这里也用到了limit，为什么没用优先队列排序算法呢？原因是，这条SQL语句是limit 1000，如果使用优先队列算法的话，需要维护的堆的大小就是1000行的(name,rowid)，<strong>超过了我设置的sort_buffer_size大小</strong>，所以只能使用<strong>归并排序算法</strong>。</p><h2 id="解决文章开头随机排序的方法"><a href="#解决文章开头随机排序的方法" class="headerlink" title="解决文章开头随机排序的方法"></a>解决文章开头随机排序的方法</h2><p><strong>方法1</strong></p><p>我们先把问题简化一下，如果只随机选择1个word值，可以怎么做呢？思路上是这样的：</p><ol><li>取得这个表的主键id的最大值M和最小值N;</li><li>用随机函数生成一个最大值到最小值之间的数 X &#x3D; (M-N)*rand() + N;</li><li>取不小于X的第一个ID的行。</li></ol><p>我们把这个算法，暂时称作随机算法1。这里，我直接给你贴一下执行语句的序列:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select max(id),min(id) into @M,@N from t ;</span><br><span class="line">set @X= floor((@M-@N+1)*rand() + @N);</span><br><span class="line">select * from t where id &gt;= @X limit 1;</span><br></pre></td></tr></table></figure><blockquote><p>这个方法效率很高，因为取max(id)和min(id)都是不需要扫描索引的，而第三步的select也可以用索引快速定位，可以认为就只扫描了3行。但实际上，这个算法本身并不严格满足题目的随机要求，因为ID中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。</p><p>比如你有4个id，分别是1、2、4、5，如果按照上面的方法，那么取到 id&#x3D;4的这一行的概率是取得其他行概率的两倍。</p><p>如果这四行的id分别是1、2、40000、40001呢？这个算法基本就能当bug来看待了。</p><p>解决：</p><p>对应单词这种总量不是很多的数据，第一感觉应该装jdk缓存或者<strong>redis缓存</strong>。由于需要随机访问，数组比较好。假如一个单词平均10个字节，10*10000，不到1M就装下了。<br>如果一定要用数据库来做，老师的方案1比较好，空洞的问题，如果单词库不变，可以在上线前<strong>整理数据</strong>，把空洞处理调。比如：原来单词存在A表，新建B表 ，执行 insert into B(word) select word from A. B的id是自增的，就会生成连续的主键。当然如果A表写比较频繁，且数据量较大，业务上禁用这种写法，RR的隔离级别会锁A表</p></blockquote><p><strong>方法2</strong></p><p>所以，为了得到严格随机的结果，你可以用下面这个流程:</p><ol><li>取得整个表的行数，并记为C。</li><li>取得 Y &#x3D; floor(C * rand())。 floor函数在这里的作用，就是取整数部分。</li><li>再用limit Y,1 取得一行。</li></ol><p>我们把这个算法，称为随机算法2。下面这段代码，就是上面流程的执行语句的序列。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select count(*) into @C from t;</span><br><span class="line">set @Y = floor(@C * rand());</span><br><span class="line">set @sql = concat(&quot;select * from t limit &quot;, @Y, &quot;,1&quot;);</span><br><span class="line">prepare stmt from @sql;</span><br><span class="line">execute stmt;</span><br><span class="line">DEALLOCATE prepare stmt;</span><br></pre></td></tr></table></figure><blockquote><p>由于limit 后面的参数不能直接跟变量，所以我在上面的代码中使用了prepare+execute的方法。你也可以把拼接SQL语句的方法写在应用程序中，会更简单些。</p><p>这个随机算法2，解决了算法1里面明显的概率不均匀问题。</p><p>MySQL处理limit Y,1 的做法就是按顺序一个一个地读出来，丢掉前Y个，然后把下一个记录作为返回结果，因此这一步需要扫描Y+1行。再加上，第一步扫描的C行，总共需要扫描C+Y+1行，执行代价比随机算法1的代价要高。</p><p>当然，随机算法2跟直接order by rand()比起来，执行代价还是小很多的。</p><p>你可能问了，如果按照这个表有10000行来计算的话，C&#x3D;10000，要是随机到比较大的Y值，那扫描行数也跟20000差不多了，接近order by rand()的扫描行数，为什么说随机算法2的代价要小很多呢？我就把这个问题留给你去课后思考吧。</p></blockquote><p><strong>方法3：即方法2取多值</strong></p><p>现在，我们再看看，如果我们按照随机算法2的思路，要随机取3个word值呢？你可以这么做：</p><ol><li>取得整个表的行数，记为C；</li><li>根据相同的随机方法得到Y1、Y2、Y3；</li><li>再执行三个limit Y, 1语句得到三行数据。</li></ol><p>我们把这个算法，称作随机算法3。下面这段代码，就是上面流程的执行语句的序列。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select count(*) into @C from t;</span><br><span class="line">set @Y1 = floor(@C * rand());</span><br><span class="line">set @Y2 = floor(@C * rand());</span><br><span class="line">set @Y3 = floor(@C * rand());</span><br><span class="line">select * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行</span><br><span class="line">select * from t limit @Y2，1；</span><br><span class="line">select * from t limit @Y3，1；</span><br></pre></td></tr></table></figure><h2 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h2><p>上面的随机算法3的总扫描行数是 C+(Y1+1)+(Y2+1)+(Y3+1)，实际上它还是可以继续优化，来进一步减少扫描行数的。</p><p>这里我给出一种方法，取Y1、Y2和Y3里面最大的一个数，记为M，最小的一个数记为N，然后执行下面这条SQL语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t limit N, M-N+1;</span><br></pre></td></tr></table></figure><p>再加上取整个表总行数的C行，这个方案的扫描行数总共只需要C+M+1行。</p><p>当然也可以先取回id值，在应用中确定了三个id值以后，再执行三次where id&#x3D;X的语句也是可以的</p><h1 id="18-讲为什么这些SQL语句逻辑相同，性能却差异巨大"><a href="#18-讲为什么这些SQL语句逻辑相同，性能却差异巨大" class="headerlink" title="18 讲为什么这些SQL语句逻辑相同，性能却差异巨大"></a>18 讲为什么这些SQL语句逻辑相同，性能却差异巨大</h1><h1 id="（即索引失效）"><a href="#（即索引失效）" class="headerlink" title="（即索引失效）"></a>（即索引失效）</h1><h2 id="索引字段使用函数"><a href="#索引字段使用函数" class="headerlink" title="索引字段使用函数"></a>索引字段使用函数</h2><p><strong>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。</strong></p><h2 id="隐式类型转换"><a href="#隐式类型转换" class="headerlink" title="隐式类型转换"></a>隐式类型转换</h2><h2 id="隐式字符编码转换"><a href="#隐式字符编码转换" class="headerlink" title="隐式字符编码转换"></a>隐式字符编码转换</h2><p>两张表，一张未utf8，一张为utf8mb4</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select d.* from tradelog l, trade_detail d where d.tradeid=l.tradeid and l.id=2; /*语句Q1*/</span><br></pre></td></tr></table></figure><p>也就是说，实际上这个语句等同于下面这个写法：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from trade_detail  where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; </span><br></pre></td></tr></table></figure><p>CONVERT()函数，在这里的意思是把输入的字符串转成utf8mb4字符集。</p><p>这就再次触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走树搜索功能。</p><p>到这里，你终于明确了，字符集不同只是条件之一，<strong>连接过程中要求在被驱动表的索引字段上加函数操作</strong></p><p><strong>两种解决办法：</strong></p><ul><li>比较常见的优化方法是，把trade_detail表上的tradeid字段的<strong>字符集也改成utf8mb4</strong>，这样就没有字符集转换的问题了。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table trade_detail modify tradeid varchar(32) CHARACTER SET utf8mb4 default null;</span><br></pre></td></tr></table></figure><ul><li>如果能够修改字段的字符集的话，是最好不过了。但如果数据量比较大，或者业务上暂时不能做这个DDL的话，那就只能采用修改SQL语句的方法了。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; </span><br></pre></td></tr></table></figure><p>这里，我主动把 l.tradeid转成utf8，就避免了被驱动表上的字符编码转换，从explain结果可以看到，这次索引走对了。</p><h1 id="19-讲为什么我只查一行的语句，也执行这么慢"><a href="#19-讲为什么我只查一行的语句，也执行这么慢" class="headerlink" title="19 讲为什么我只查一行的语句，也执行这么慢"></a>19 讲为什么我只查一行的语句，也执行这么慢</h1><h2 id="影响查询速度的几种情况"><a href="#影响查询速度的几种情况" class="headerlink" title="影响查询速度的几种情况"></a>影响查询速度的几种情况</h2><p>为了便于描述，我还是构造一个表，基于这个表来说明今天的问题。这个表有两个字段id和c，并且我在里面插入了10万行记录。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `c` int(11) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`)</span><br><span class="line">) ENGINE=InnoDB;</span><br></pre></td></tr></table></figure><h3 id="第一类：查询长时间不返回"><a href="#第一类：查询长时间不返回" class="headerlink" title="第一类：查询长时间不返回"></a>第一类：查询长时间不返回</h3><p>如图1所示，在表t执行下面的SQL语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t where id=1;</span><br></pre></td></tr></table></figure><p>查询结果长时间不返回。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/8707b79d5ed906950749f5266014f22a.png" alt="img"></p><p>​ 图1 查询长时间不返回</p><p>一般碰到这种情况的话，大概率是表t被锁住了。接下来分析原因的时候，一般都是首先执行一下show processlist命令，看看当前语句处于什么状态。</p><p>然后我们再针对每种状态，去分析它们产生的原因、如何复现，以及如何处理。</p><h4 id="等MDL锁"><a href="#等MDL锁" class="headerlink" title="等MDL锁"></a>等MDL锁</h4><p>如图2所示，就是使用show processlist命令查看Waiting for table metadata lock的示意图。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/5008d7e9e22be88a9c80916df4f4b328.png" alt="img"></p><p>​ 图2 Waiting for table metadata lock状态示意图</p><p>出现<strong>这个状态表示的是，现在有一个线程正在表t上请求或者持有MDL写锁，把select语句堵住了。</strong></p><p>这类问题的处理方式，就是找到谁持有MDL写锁，然后把它kill掉。</p><p>但是，由于在show processlist的结果里面，session A的Command列是“Sleep”，导致查找起来很不方便。不过有了performance_schema和sys系统库以后，就方便多了。（MySQL启动时需要设置performance_schema&#x3D;on，相比于设置为off会有10%左右的性能损失)</p><p>通过查询sys.schema_table_lock_waits这张表，我们就可以直接找出造成阻塞的process id，把这个连接用kill 命令断开即可。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select blocking_pid from sys.schema_table_lock_waits;</span><br></pre></td></tr></table></figure><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/74fb24ba3826e3831eeeff1670990c01.png" alt="img"></p><p>​ 图4 查获加表锁的线程id</p><h4 id="等flush"><a href="#等flush" class="headerlink" title="等flush"></a>等flush</h4><p>接下来，我给你举另外一种查询被堵住的情况。</p><p>我在表t上，执行下面的SQL语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from information_schema.processlist where id=1;</span><br></pre></td></tr></table></figure><p>这里，我先卖个关子。</p><p>你可以看一下图5。我查出来这个线程的状态是Waiting for table flush，你可以设想一下这是什么原因。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/2d8250398bc7f8f7dce8b6b1923c3724.png" alt="img"></p><p>​ 图5 Waiting for table flush状态示意图</p><p>这个状态表示的是，现在有一个线程正要对表t做flush操作。MySQL里面对表做flush操作的用法，一般有以下两个：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flush tables t with read lock;</span><br><span class="line"></span><br><span class="line">flush tables with read lock;</span><br></pre></td></tr></table></figure><p>这两个flush语句，如果指定表t的话，代表的是只关闭表t；如果没有指定具体的表名，则表示关闭MySQL里所有打开的表。</p><p>但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。</p><p>所以，出现Waiting for table flush状态的可能情况是：有一个flush tables命令被别的语句堵住了，然后它又堵住了我们的select语句。</p><p>现在，我们一起来复现一下这种情况，<strong>复现步骤</strong>如图6所示：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/2bbc77cfdb118b0d9ef3fdd679d0a69c.png" alt="img"></p><p>​ 图6 Waiting for table flush的复现步骤</p><h4 id="等行锁"><a href="#等行锁" class="headerlink" title="等行锁"></a>等行锁</h4><p>现在，经过了表级锁的考验，我们的select 语句终于来到引擎里了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t where id=1 lock in share mode; </span><br></pre></td></tr></table></figure><p>上面这条语句的用法你也很熟悉了，我们在第8篇<a target="_blank" rel="noopener" href="https://time.geekbang.org/column/article/70562">《事务到底是隔离的还是不隔离的？》</a>文章介绍当前读时提到过。</p><p>由于访问id&#x3D;1这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的select语句就会被堵住。</p><p>复现步骤和现场如下：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/3e68326b967701c59770612183277475.png" alt="img"></p><p>​ 图 8 行锁复现</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/3c266e23fc307283aa94923ecbbc738f.png" alt="img"></p><p>图 9 行锁show processlist 现场</p><p>显然，session A启动了事务，占有写锁，还不提交，是导致session B被堵住的原因。</p><p>这个问题并不难分析，但问题是怎么查出是谁占着这个写锁。如果你用的是MySQL 5.7版本，可以通过sys.innodb_lock_waits 表查到。</p><p>查询方法是：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t sys.innodb_lock_waits where locked_table=`&#x27;test&#x27;.&#x27;t&#x27;`\G</span><br></pre></td></tr></table></figure><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)实战45讲笔记.assets/d8603aeb4eaad3326699c13c46379118.png" alt="img" style="zoom:67%"><p>​ 图10 通过sys.innodb_lock_waits 查行锁</p><p>可以看到，这个信息很全，4号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是KILL QUERY 4或KILL 4。</p><p>不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止4号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是update语句，这个语句已经是之前执行完成了的，现在执行KILL QUERY，无法让这个事务去掉id&#x3D;1上的行锁。</p><p>实际上，KILL 4才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了id&#x3D;1上的行锁。</p><h3 id="第二类：查询慢"><a href="#第二类：查询慢" class="headerlink" title="第二类：查询慢"></a>第二类：查询慢</h3><p>经过了重重封“锁”，我们再来看看一些查询慢的例子。</p><h4 id="全表扫描"><a href="#全表扫描" class="headerlink" title="全表扫描"></a>全表扫描</h4><p>先来看一条你一定知道原因的SQL语句：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t where c=50000 limit 1;</span><br></pre></td></tr></table></figure><p>由于字段c上没有索引，这个语句只能走id主键顺序扫描，因此需要扫描5万行。</p><p>作为确认，你可以看一下慢查询日志。注意，这里为了把所有语句记录到slow log里，我在连接后先执行了 set long_query_time&#x3D;0，将慢查询日志的时间阈值设置为0。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/d8b2b5f97c60ae4fc4a03c616847503c.png" alt="img"></p><p>​ 图11 全表扫描5万行的slow log</p><p>Rows_examined显示扫描了50000行。你可能会说，不是很慢呀，11.5毫秒就返回了，我们线上一般都配置超过1秒才算慢查询。但你要记住：<strong>坏查询不一定是慢查询</strong>。我们这个例子里面只有10万行记录，数据量大起来的话，执行时间就线性涨上去了。</p><p>扫描行数多，所以执行慢，这个很好理解。</p><h4 id="undo链太长"><a href="#undo链太长" class="headerlink" title="undo链太长"></a>undo链太长</h4><p>但是接下来，我们再看一个只扫描一行，但是执行很慢的语句。</p><p>如图12所示，是这个例子的slow log。可以看到，执行的语句是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t where id=1；</span><br></pre></td></tr></table></figure><p>虽然扫描行数是1，但执行时间却长达800毫秒。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/66f26bb885401e8e460451ff6b0c0746.png" alt="img"></p><p>​ 图12 扫描一行却执行得很慢</p><p>是不是有点奇怪呢，这些时间都花在哪里了？</p><p>如果我把这个slow log的截图再往下拉一点，你可以看到下一个语句，select * from t where id&#x3D;1 lock in share mode，执行时扫描行数也是1行，执行时间是0.2毫秒。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/bde83e269d9fa185b27900c8aa8137d2.png" alt="img"></p><p>​ 图 13 加上lock in share mode的slow log</p><p>看上去是不是更奇怪了？按理说lock in share mode还要加锁，时间应该更长才对啊。</p><p>可能有的同学已经有答案了。如果你还没有答案的话，我再给你一个提示信息，图14是这两个语句的执行输出结果。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/1fbb84bb392b6bfa93786fe032690b1c.png" alt="img"></p><p>​ 图14 两个语句的输出结果</p><p>第一个语句的查询结果里c&#x3D;1，带lock in share mode的语句返回的是c&#x3D;1000001。看到这里应该有更多的同学知道原因了。如果你还是没有头绪的话，也别着急。我先跟你说明一下复现步骤，再分析原因。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/84667a3449dc846e393142600ee7a2ff.png" alt="img"></p><p>​ 图15 复现步骤</p><p>你看到了，session A先用start transaction with consistent snapshot命令启动了一个事务，之后session B才开始执行update 语句。</p><p>session B执行完100万次update语句后，id&#x3D;1这一行处于什么状态呢？你可以从图16中找到答案。</p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)实战45讲笔记.assets/46bb9f5e27854678bfcaeaf0c3b8a98c.png" alt="img" style="zoom:50%"><p>​ 图16 id&#x3D;1的数据状态</p><p>session B更新完100万次，生成了100万个回滚日志(undo log)。</p><p>带lock in share mode的SQL语句，是当前读，因此会直接读到1000001这个结果，所以速度很快；而select * from t where id&#x3D;1这个语句，是一致性读，因此需要从1000001开始，依次执行undo log，执行了100万次以后，才将1这个结果返回。</p><p>注意，undo log里记录的其实是“把2改成1”，“把3改成2”这样的操作逻辑，画成减1的目的是方便你看图。</p><h1 id="20-讲幻读是什么，幻读有什么问题"><a href="#20-讲幻读是什么，幻读有什么问题" class="headerlink" title="20 讲幻读是什么，幻读有什么问题"></a>20 讲幻读是什么，幻读有什么问题</h1><h2 id="非索引字段更新语句的加锁情况"><a href="#非索引字段更新语句的加锁情况" class="headerlink" title="非索引字段更新语句的加锁情况"></a>非索引字段更新语句的加锁情况</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `t` (</span><br><span class="line">  `id` int(11) NOT NULL,</span><br><span class="line">  `c` int(11) DEFAULT NULL,</span><br><span class="line">  `d` int(11) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  KEY `c` (`c`)</span><br><span class="line">) ENGINE=InnoDB;</span><br><span class="line"></span><br><span class="line">insert into t values(0,0,0),(5,5,5),</span><br><span class="line">(10,10,10),(15,15,15),(20,20,20),(25,25,25);</span><br></pre></td></tr></table></figure><p>这个表除了主键id外，还有一个索引c，初始化语句在表中插入了6行数据。</p><p>上期我留给你的问题是，下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">begin;</span><br><span class="line">select * from t where d=5 for update;</span><br><span class="line">commit;</span><br></pre></td></tr></table></figure><blockquote><p>先说结论：</p><ul><li>RC级别下，非索引字段的更新操作会对全表每一条记录加行锁</li><li>RR级别下，非索引字段的更新操作会对全表每一条记录邻间锁（记录锁+间隙锁）</li></ul></blockquote><h2 id="幻读"><a href="#幻读" class="headerlink" title="幻读"></a>幻读</h2><p>幻读指的是<strong>一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。</strong></p><p>这里，我需要对“幻读”做一个说明：</p><ol><li>在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，<strong>幻读在“当前读”下才会出现</strong><ul><li>若是快照读，MVCC机制已经解决了幻读问题</li><li>若是当前读，采用加间隙锁的方式解决幻读</li></ul></li><li>上面session B的修改结果，被session A之后的select语句用“当前读”看到，不能称为幻读。幻读仅<strong>专指“新插入的行”</strong>。</li></ol><h2 id="如何解决幻读？"><a href="#如何解决幻读？" class="headerlink" title="如何解决幻读？"></a>如何解决幻读？</h2><p>现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是<strong>间隙锁(Gap Lock)。</strong></p><p>顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表t，初始化插入了6个记录，这就产生了7个间隙。</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/image-20230930153653250.png" alt="image-20230930153653250"></p><p>这样，当你执行 select * from t where d&#x3D;5 for update的时候，就不止是给数据库中已有的6个记录加上了行锁，还同时加了7个间隙锁。这样就确保了无法再插入新的记录。</p><p>也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。</p><p><strong>间隙锁之间都不存在冲突关系。</strong></p><p>这句话不太好理解，我给你举个例子：</p><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/../../image/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0.assets/7c37732d936650f1cda7dbf27daf7498.png" alt="img"></p><p>​ 图7 间隙锁之间不互锁</p><p>这里session B并不会被堵住。因为表t里并没有c&#x3D;7这个记录，因此session A加的是间隙锁(5,10)。而session B也是在这个间隙加的间隙锁。它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。</p><p>间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间。也就是说，我们的表t初始化以后，如果用select * from t for update要把整个表所有记录锁起来，就形成了7个next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +suprenum]。</p><p><strong>间隙锁和next-key lock的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。</strong></p><p>间隙锁容易造成<strong>死锁</strong>，且<strong>间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的</strong></p><blockquote><p><strong>间隙锁是在可重复读隔离级别下才会生效</strong>的。所以，你如果把隔离级别设置为<strong>读提交</strong>的话，就没有间隙锁了。但同时，你要解决可能出现的数据和日志不一致问题，需要<strong>把binlog格式设置为row</strong>。这，也是现在不少公司使用的配置组合。</p></blockquote></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://blog.hahhome.top/about">spongehah</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/">https://blog.hahhome.top/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.hahhome.top" target="_blank">HahHome</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/MySQL/">MySQL</a></div><div class="post_share"><div class="social-share" data-image="/img/cover_default_img/02.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="/pluginsSrc/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="/pluginsSrc/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.webp" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/wechat.webp" alt="微信"></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.webp" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/alipay.webp" alt="支付宝"></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/blog/Redis/" title="Redis安装和常见数据类型命令"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/07.webp" onerror='onerror=null,src="/img/404.webp"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Redis安装和常见数据类型命令</div></div></a></div><div class="next-post pull-right"><a href="/blog/MySQL(5)%E6%97%A5%E5%BF%97%E4%B8%8E%E5%A4%87%E4%BB%BD%E7%AF%87/" title="MySQL(5)日志与备份篇"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/07.webp" onerror='onerror=null,src="/img/404.webp"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">MySQL(5)日志与备份篇</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/blog/MySQL(1)%E5%9F%BA%E7%A1%80%E7%AF%87/" title="MySQL(1)基础篇"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/01.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-01</div><div class="title">MySQL(1)基础篇</div></div></a></div><div><a href="/blog/MySQL(2)%E6%9E%B6%E6%9E%84%E7%AF%87/" title="MySQL(2)架构篇"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/02.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-01</div><div class="title">MySQL(2)架构篇</div></div></a></div><div><a href="/blog/MySQL(5)%E6%97%A5%E5%BF%97%E4%B8%8E%E5%A4%87%E4%BB%BD%E7%AF%87/" title="MySQL(5)日志与备份篇"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/07.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-01</div><div class="title">MySQL(5)日志与备份篇</div></div></a></div><div><a href="/blog/MySQL(4)%E4%BA%8B%E5%8A%A1%E7%AF%87/" title="MySQL(4)事务篇"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/01.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-01</div><div class="title">MySQL(4)事务篇</div></div></a></div><div><a href="/blog/MySQL(3)%E7%B4%A2%E5%BC%95%E5%92%8C%E8%B0%83%E4%BC%98%E7%AF%87/" title="MySQL(3)索引和调优篇"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/07.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-01</div><div class="title">MySQL(3)索引和调优篇</div></div></a></div></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Twikoo</span><span class="switch-btn"></span><span class="second-comment">Gitalk</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.webp" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">spongehah</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">27</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">7</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="http://47.115.207.49/"><i class="fas fa-home"></i><span>The another blog</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/spongehah" target="_blank" title="Github"><i class="fab fa-github" style="color:#24292e"></i></a><a class="social-icon" href="/spongehah@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color:#4a7dbe"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到HahHome！平时我会定期更新本地的笔记到这个博客上，如需实时笔记请关注我的github或者gitee<br>更多笔记请点击The another blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#01-%E8%AE%B2%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%EF%BC%9A%E4%B8%80%E6%9D%A1SQL%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84"><span class="toc-number">1.</span> <span class="toc-text">01 讲基础架构：一条SQL查询语句是如何执行的</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E8%BF%9E%E6%8E%A5%E5%99%A8"><span class="toc-number">1.1.</span> <span class="toc-text">第一步：连接器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E6%8E%A5sleep"><span class="toc-number">1.1.1.</span> <span class="toc-text">连接sleep</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%95%BF%E8%BF%9E%E6%8E%A5"><span class="toc-number">1.1.2.</span> <span class="toc-text">长连接</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E6%9F%A5%E8%AF%A2%E7%BC%93%E5%AD%98"><span class="toc-number">1.2.</span> <span class="toc-text">第二步：查询缓存</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E5%88%86%E6%9E%90%E5%99%A8"><span class="toc-number">1.3.</span> <span class="toc-text">第三步：分析器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9A%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">1.4.</span> <span class="toc-text">第四步：优化器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E6%AD%A5%EF%BC%9A%E6%89%A7%E8%A1%8C%E5%99%A8"><span class="toc-number">1.5.</span> <span class="toc-text">第五步：执行器</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#02-%E8%AE%B2%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%EF%BC%9A%E4%B8%80%E6%9D%A1SQL%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84"><span class="toc-number">2.</span> <span class="toc-text">02 讲日志系统：一条SQL更新语句是如何执行的</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#redo-log"><span class="toc-number">2.1.</span> <span class="toc-text">redo log</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#binlog"><span class="toc-number">2.2.</span> <span class="toc-text">binlog</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B"><span class="toc-number">2.3.</span> <span class="toc-text">更新语句执行过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#redo-log%E7%9A%84%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4"><span class="toc-number">2.4.</span> <span class="toc-text">redo log的两阶段提交</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#03-%E8%AE%B2%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%94%B9%E4%BA%86%E6%88%91%E8%BF%98%E7%9C%8B%E4%B8%8D%E8%A7%81"><span class="toc-number">3.</span> <span class="toc-text">03 讲事务隔离：为什么你改了我还看不见</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#04-%E8%AE%B2%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95-%E4%B8%8A"><span class="toc-number">4.</span> <span class="toc-text">04 讲深入浅出索引(上)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hash%E7%B4%A2%E5%BC%95"><span class="toc-number">4.1.</span> <span class="toc-text">Hash索引</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84"><span class="toc-number">4.2.</span> <span class="toc-text">有序数组</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91"><span class="toc-number">4.3.</span> <span class="toc-text">二叉搜索树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#B-%E6%A0%91"><span class="toc-number">4.4.</span> <span class="toc-text">B+树</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#05-%E8%AE%B2%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95-%E4%B8%8B"><span class="toc-number">5.</span> <span class="toc-text">05 讲深入浅出索引(下)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9E%E8%A1%A8%E8%BF%87%E7%A8%8B"><span class="toc-number">5.1.</span> <span class="toc-text">回表过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95"><span class="toc-number">5.2.</span> <span class="toc-text">覆盖索引</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%80%E5%B7%A6%E5%89%8D%E7%BC%80%E5%8E%9F%E5%88%99"><span class="toc-number">5.3.</span> <span class="toc-text">最左前缀原则</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8"><span class="toc-number">5.4.</span> <span class="toc-text">索引下推</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#06-%E8%AE%B2%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81%EF%BC%9A%E7%BB%99%E8%A1%A8%E5%8A%A0%E4%B8%AA%E5%AD%97%E6%AE%B5%E6%80%8E%E4%B9%88%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A%E9%98%BB%E7%A2%8D"><span class="toc-number">6.</span> <span class="toc-text">06 讲全局锁和表锁：给表加个字段怎么有这么多阻碍</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E9%94%81"><span class="toc-number">6.1.</span> <span class="toc-text">全局锁</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%A8%E7%BA%A7%E9%94%81"><span class="toc-number">6.2.</span> <span class="toc-text">表级锁</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#07-%E8%AE%B2%E8%A1%8C%E9%94%81%E5%8A%9F%E8%BF%87%EF%BC%9A%E6%80%8E%E4%B9%88%E5%87%8F%E5%B0%91%E8%A1%8C%E9%94%81%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">7.</span> <span class="toc-text">07 讲行锁功过：怎么减少行锁对性能的影响</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%A4%E9%98%B6%E6%AE%B5%E9%94%81"><span class="toc-number">7.1.</span> <span class="toc-text">两阶段锁</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%BB%E9%94%81%E5%92%8C%E6%AD%BB%E9%94%81%E6%A3%80%E6%B5%8B"><span class="toc-number">7.2.</span> <span class="toc-text">死锁和死锁检测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%E7%94%B1%E7%83%AD%E7%82%B9%E8%A1%8C%E6%9B%B4%E6%96%B0%E5%AF%BC%E8%87%B4%E7%9A%84%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">7.3.</span> <span class="toc-text">怎么解决由热点行更新导致的性能问题？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#08-%E8%AE%B2%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84%E8%BF%98%E6%98%AF%E4%B8%8D%E9%9A%94%E7%A6%BB%E7%9A%84"><span class="toc-number">8.</span> <span class="toc-text">08 讲事务到底是隔离的还是不隔离的</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#read-view%E7%9A%84%E7%94%9F%E6%88%90%E4%BB%A5%E5%8F%8A%E5%BD%93%E5%89%8D%E8%AF%BB"><span class="toc-number">8.1.</span> <span class="toc-text">read view的生成以及当前读</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#read-view%E5%8E%9F%E7%90%86"><span class="toc-number">8.1.1.</span> <span class="toc-text">read view原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%93%E5%89%8D%E8%AF%BB"><span class="toc-number">8.1.2.</span> <span class="toc-text">当前读</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#09-%E8%AE%B2%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%EF%BC%8C%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E9%80%89%E6%8B%A9"><span class="toc-number">9.</span> <span class="toc-text">09 讲普通索引和唯一索引，应该怎么选择</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">9.1.</span> <span class="toc-text">查询过程的区别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E8%BF%87%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">9.2.</span> <span class="toc-text">更新过程的区别</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#change-buffer"><span class="toc-number">9.2.1.</span> <span class="toc-text">change buffer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E5%8C%BA%E5%88%AB"><span class="toc-number">9.2.2.</span> <span class="toc-text">更新区别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#change-buffer%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">9.3.</span> <span class="toc-text">change buffer的使用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#change-buffer-%E5%92%8C-redo-log"><span class="toc-number">9.4.</span> <span class="toc-text">change buffer 和 redo log</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#10-%E8%AE%B2MySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%97%B6%E5%80%99%E4%BC%9A%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95"><span class="toc-number">10.</span> <span class="toc-text">10 讲MySQL为什么有时候会选错索引</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MySQL%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95%E4%B8%BE%E4%BE%8B"><span class="toc-number">10.1.</span> <span class="toc-text">MySQL选错索引举例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8%E7%9A%84%E9%80%BB%E8%BE%91"><span class="toc-number">10.2.</span> <span class="toc-text">优化器的逻辑</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%95%B0%E7%BB%9F%E8%AE%A1%E6%96%B9%E6%B3%95"><span class="toc-number">10.2.1.</span> <span class="toc-text">基数统计方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E4%BC%B0%E6%89%AB%E6%8F%8F%E8%A1%8C%E6%95%B0"><span class="toc-number">10.2.2.</span> <span class="toc-text">预估扫描行数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%AD%A3%E7%BB%9F%E8%AE%A1%E4%BF%A1%E6%81%AF"><span class="toc-number">10.2.3.</span> <span class="toc-text">修正统计信息</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="toc-number">10.2.4.</span> <span class="toc-text">第二个例子</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95%E9%80%89%E6%8B%A9%E5%BC%82%E5%B8%B8%E5%92%8C%E5%A4%84%E7%90%86"><span class="toc-number">10.3.</span> <span class="toc-text">索引选择异常和处理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#11-%E8%AE%B2%E6%80%8E%E4%B9%88%E7%BB%99%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AD%97%E6%AE%B5%E5%8A%A0%E7%B4%A2%E5%BC%95"><span class="toc-number">11.</span> <span class="toc-text">11 讲怎么给字符串字段加索引</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%89%8D%E7%BC%80%E7%B4%A2%E5%BC%95"><span class="toc-number">11.1.</span> <span class="toc-text">字符串前缀索引</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E5%AE%9A%E4%B9%89%E5%A5%BD%E5%89%8D%E7%BC%80%E7%B4%A2%E5%BC%95"><span class="toc-number">11.2.</span> <span class="toc-text">怎么定义好前缀索引</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E7%BC%80%E7%B4%A2%E5%BC%95%E5%AF%B9%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">11.3.</span> <span class="toc-text">前缀索引对覆盖索引的影响</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B4%A2%E5%BC%95%E7%9A%84%E5%85%B6%E4%BB%96%E6%96%B9%E5%BC%8F"><span class="toc-number">11.4.</span> <span class="toc-text">定义字符串索引的其他方式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%80%92%E5%BA%8F%E5%AD%98%E5%82%A8"><span class="toc-number">11.4.1.</span> <span class="toc-text">倒序存储</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#hash%E5%AD%97%E6%AE%B5"><span class="toc-number">11.4.2.</span> <span class="toc-text">hash字段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%80%92%E5%BA%8F%E5%92%8Chash%E7%9A%84%E5%BC%82%E5%90%8C"><span class="toc-number">11.4.3.</span> <span class="toc-text">倒序和hash的异同</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#12-%E8%AE%B2%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E7%9A%84MySQL%E4%BC%9A%E2%80%9C%E6%8A%96%E2%80%9D%E4%B8%80%E4%B8%8B"><span class="toc-number">12.</span> <span class="toc-text">12 讲为什么我的MySQL会“抖”一下</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E7%AA%81%E7%84%B6%E5%8F%98%E6%85%A2%EF%BC%9F"><span class="toc-number">12.1.</span> <span class="toc-text">为什么会突然变慢？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9Aflush"><span class="toc-number">12.2.</span> <span class="toc-text">什么时候会flush</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#flush%E6%93%8D%E4%BD%9C%E5%AF%B9%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">12.3.</span> <span class="toc-text">flush操作对系统性能的影响</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#InnoDB%E5%88%B7%E8%84%8F%E9%A1%B5%E9%80%9F%E5%BA%A6%E7%9A%84%E6%8E%A7%E5%88%B6%E7%AD%96%E7%95%A5"><span class="toc-number">12.4.</span> <span class="toc-text">InnoDB刷脏页速度的控制策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E6%9C%BAIO%E8%83%BD%E5%8A%9B"><span class="toc-number">12.4.1.</span> <span class="toc-text">主机IO能力</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%84%8F%E9%A1%B5%E6%AF%94%E4%BE%8B"><span class="toc-number">12.4.2.</span> <span class="toc-text">脏页比例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%B7%E8%84%8F%E9%A1%B5%E7%9A%84%E9%80%9F%E5%BA%A6%E8%AE%A1%E7%AE%97"><span class="toc-number">12.4.3.</span> <span class="toc-text">刷脏页的速度计算</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#13-%E8%AE%B2%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A1%A8%E6%95%B0%E6%8D%AE%E5%88%A0%E6%8E%89%E4%B8%80%E5%8D%8A%EF%BC%8C%E8%A1%A8%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F%E4%B8%8D%E5%8F%98"><span class="toc-number">13.</span> <span class="toc-text">13 讲为什么表数据删掉一半，表文件大小不变</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0innodb-file-per-table"><span class="toc-number">13.1.</span> <span class="toc-text">参数innodb_file_per_table</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#delete%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE"><span class="toc-number">13.2.</span> <span class="toc-text">delete删除数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%EF%BC%9A%E9%87%8D%E5%BB%BA%E8%A1%A8"><span class="toc-number">13.3.</span> <span class="toc-text">解决方法：重建表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Online-%E5%92%8C-inplace"><span class="toc-number">13.4.</span> <span class="toc-text">Online 和 inplace</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#14-%E8%AE%B2count-%E8%BF%99%E4%B9%88%E6%85%A2%EF%BC%8C%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E"><span class="toc-number">14.</span> <span class="toc-text">14 讲count(*)这么慢，我该怎么办</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#count-%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F"><span class="toc-number">14.1.</span> <span class="toc-text">count(*)的实现方式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%94%A8%E7%BC%93%E5%AD%98%E7%B3%BB%E7%BB%9F%E4%BF%9D%E5%AD%98%E8%AE%A1%E6%95%B0"><span class="toc-number">14.2.</span> <span class="toc-text">用缓存系统保存计数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BF%9D%E5%AD%98%E8%AE%A1%E6%95%B0"><span class="toc-number">14.3.</span> <span class="toc-text">在数据库保存计数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E7%9A%84count%E7%94%A8%E6%B3%95"><span class="toc-number">14.4.</span> <span class="toc-text">不同的count用法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#15-%E8%AE%B2%E7%AD%94%E7%96%91%E6%96%87%E7%AB%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E6%97%A5%E5%BF%97%E5%92%8C%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98"><span class="toc-number">15.</span> <span class="toc-text">15 讲答疑文章（一）：日志和索引相关问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E4%B8%8D%E5%90%8C%E5%BC%82%E5%B8%B8%E9%87%8D%E5%90%AF%E7%9A%84%E7%8E%B0%E8%B1%A1"><span class="toc-number">15.1.</span> <span class="toc-text">两阶段提交不同异常重启的现象</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%BD%E9%97%AE1%EF%BC%9AMySQL%E6%80%8E%E4%B9%88%E7%9F%A5%E9%81%93binlog%E6%98%AF%E5%AE%8C%E6%95%B4%E7%9A%84"><span class="toc-number">15.1.0.1.</span> <span class="toc-text">追问1：MySQL怎么知道binlog是完整的?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%BD%E9%97%AE2%EF%BC%9Aredo-log-%E5%92%8C-binlog%E6%98%AF%E6%80%8E%E4%B9%88%E5%85%B3%E8%81%94%E8%B5%B7%E6%9D%A5%E7%9A%84"><span class="toc-number">15.1.0.2.</span> <span class="toc-text">追问2：redo log 和 binlog是怎么关联起来的?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%BD%E9%97%AE3%EF%BC%9A%E5%A4%84%E4%BA%8Eprepare%E9%98%B6%E6%AE%B5%E7%9A%84redo-log%E5%8A%A0%E4%B8%8A%E5%AE%8C%E6%95%B4binlog%EF%BC%8C%E9%87%8D%E5%90%AF%E5%B0%B1%E8%83%BD%E6%81%A2%E5%A4%8D%EF%BC%8CMySQL%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%99%E4%B9%88%E8%AE%BE%E8%AE%A1"><span class="toc-number">15.1.0.3.</span> <span class="toc-text">追问3：处于prepare阶段的redo log加上完整binlog，重启就能恢复，MySQL为什么要这么设计?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%BD%E9%97%AE4%EF%BC%9A%E5%A6%82%E6%9E%9C%E8%BF%99%E6%A0%B7%E7%9A%84%E8%AF%9D%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E8%A6%81%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E5%91%A2%EF%BC%9F%E5%B9%B2%E8%84%86%E5%85%88redo-log%E5%86%99%E5%AE%8C%EF%BC%8C%E5%86%8D%E5%86%99binlog%E3%80%82%E5%B4%A9%E6%BA%83%E6%81%A2%E5%A4%8D%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%BF%85%E9%A1%BB%E5%BE%97%E4%B8%A4%E4%B8%AA%E6%97%A5%E5%BF%97%E9%83%BD%E5%AE%8C%E6%95%B4%E6%89%8D%E5%8F%AF%E4%BB%A5%E3%80%82%E6%98%AF%E4%B8%8D%E6%98%AF%E4%B8%80%E6%A0%B7%E7%9A%84%E9%80%BB%E8%BE%91%EF%BC%9F"><span class="toc-number">15.1.0.4.</span> <span class="toc-text">追问4：如果这样的话，为什么还要两阶段提交呢？干脆先redo log写完，再写binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%BD%E9%97%AE5%EF%BC%9A%E4%B8%8D%E5%BC%95%E5%85%A5%E4%B8%A4%E4%B8%AA%E6%97%A5%E5%BF%97%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%B2%A1%E6%9C%89%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%8F%90%E4%BA%A4%E7%9A%84%E5%BF%85%E8%A6%81%E4%BA%86%E3%80%82%E5%8F%AA%E7%94%A8binlog%E6%9D%A5%E6%94%AF%E6%8C%81%E5%B4%A9%E6%BA%83%E6%81%A2%E5%A4%8D%EF%BC%8C%E5%8F%88%E8%83%BD%E6%94%AF%E6%8C%81%E5%BD%92%E6%A1%A3%EF%BC%8C%E4%B8%8D%E5%B0%B1%E5%8F%AF%E4%BB%A5%E4%BA%86%EF%BC%9F"><span class="toc-number">15.1.0.5.</span> <span class="toc-text">追问5：不引入两个日志，也就没有两阶段提交的必要了。只用binlog来支持崩溃恢复，又能支持归档，不就可以了？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%BD%E9%97%AE6%EF%BC%9A%E9%82%A3%E8%83%BD%E4%B8%8D%E8%83%BD%E5%8F%8D%E8%BF%87%E6%9D%A5%EF%BC%8C%E5%8F%AA%E7%94%A8redo-log%EF%BC%8C%E4%B8%8D%E8%A6%81binlog%EF%BC%9F"><span class="toc-number">15.1.0.6.</span> <span class="toc-text">追问6：那能不能反过来，只用redo log，不要binlog？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%BD%E9%97%AE7%EF%BC%9Aredo-log%E4%B8%80%E8%88%AC%E8%AE%BE%E7%BD%AE%E5%A4%9A%E5%A4%A7%EF%BC%9F"><span class="toc-number">15.1.0.7.</span> <span class="toc-text">追问7：redo log一般设置多大？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%BD%E9%97%AE8%EF%BC%9A%E6%AD%A3%E5%B8%B8%E8%BF%90%E8%A1%8C%E4%B8%AD%E7%9A%84%E5%AE%9E%E4%BE%8B%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E5%90%8E%E7%9A%84%E6%9C%80%E7%BB%88%E8%90%BD%E7%9B%98%EF%BC%8C%E6%98%AF%E4%BB%8Eredo-log%E6%9B%B4%E6%96%B0%E8%BF%87%E6%9D%A5%E7%9A%84%E8%BF%98%E6%98%AF%E4%BB%8Ebuffer-pool%E6%9B%B4%E6%96%B0%E8%BF%87%E6%9D%A5%E7%9A%84%E5%91%A2%EF%BC%9F"><span class="toc-number">15.1.0.8.</span> <span class="toc-text">追问8：正常运行中的实例，数据写入后的最终落盘，是从redo log更新过来的还是从buffer pool更新过来的呢？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%BD%E9%97%AE9%EF%BC%9Aredo-log-buffer%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E6%98%AF%E5%85%88%E4%BF%AE%E6%94%B9%E5%86%85%E5%AD%98%EF%BC%8C%E8%BF%98%E6%98%AF%E5%85%88%E5%86%99redo-log%E6%96%87%E4%BB%B6%EF%BC%9F"><span class="toc-number">15.1.0.9.</span> <span class="toc-text">追问9：redo log buffer是什么？是先修改内存，还是先写redo log文件？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E4%B8%80%E6%A0%B7%E7%9A%84%E6%95%B0%E6%8D%AEMySQL%E4%BC%9A%E6%80%8E%E6%A0%B7%E8%BF%90%E8%A1%8C"><span class="toc-number">15.2.</span> <span class="toc-text">修改一样的数据MySQL会怎样运行</span></a></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#16-%E8%AE%B2%E2%80%9Corderby%E2%80%9D%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84"><span class="toc-number">16.</span> <span class="toc-text">16 讲“orderby”是怎么工作的</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#filesort%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F"><span class="toc-number">16.1.</span> <span class="toc-text">filesort归并排序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%AD%97%E6%AE%B5%E6%8E%92%E5%BA%8F"><span class="toc-number">16.1.1.</span> <span class="toc-text">全字段排序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#rowid%E6%8E%92%E5%BA%8F"><span class="toc-number">16.1.2.</span> <span class="toc-text">rowid排序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%AD%97%E6%AE%B5%E6%8E%92%E5%BA%8F-VS-rowid%E6%8E%92%E5%BA%8F"><span class="toc-number">16.1.3.</span> <span class="toc-text">全字段排序 VS rowid排序</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95%E6%8E%92%E5%BA%8F"><span class="toc-number">16.2.</span> <span class="toc-text">索引排序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-number">16.3.</span> <span class="toc-text">问题</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#17-orderby-2-%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E5%9C%B0%E6%98%BE%E7%A4%BA%E9%9A%8F%E6%9C%BA%E6%B6%88%E6%81%AF"><span class="toc-number">17.</span> <span class="toc-text">17 orderby 2 如何正确地显示随机消息</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E4%B8%B4%E6%97%B6%E8%A1%A8"><span class="toc-number">17.1.</span> <span class="toc-text">内存临时表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A3%81%E7%9B%98%E4%B8%B4%E6%97%B6%E8%A1%A8InnoDB"><span class="toc-number">17.2.</span> <span class="toc-text">磁盘临时表InnoDB</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97%E6%8E%92%E5%BA%8F"><span class="toc-number">17.2.1.</span> <span class="toc-text">优先队列排序</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%87%E7%AB%A0%E5%BC%80%E5%A4%B4%E9%9A%8F%E6%9C%BA%E6%8E%92%E5%BA%8F%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">17.3.</span> <span class="toc-text">解决文章开头随机排序的方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98-1"><span class="toc-number">17.4.</span> <span class="toc-text">问题</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#18-%E8%AE%B2%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%BA%9BSQL%E8%AF%AD%E5%8F%A5%E9%80%BB%E8%BE%91%E7%9B%B8%E5%90%8C%EF%BC%8C%E6%80%A7%E8%83%BD%E5%8D%B4%E5%B7%AE%E5%BC%82%E5%B7%A8%E5%A4%A7"><span class="toc-number">18.</span> <span class="toc-text">18 讲为什么这些SQL语句逻辑相同，性能却差异巨大</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%EF%BC%88%E5%8D%B3%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%EF%BC%89"><span class="toc-number">19.</span> <span class="toc-text">（即索引失效）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95%E5%AD%97%E6%AE%B5%E4%BD%BF%E7%94%A8%E5%87%BD%E6%95%B0"><span class="toc-number">19.1.</span> <span class="toc-text">索引字段使用函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%90%E5%BC%8F%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2"><span class="toc-number">19.2.</span> <span class="toc-text">隐式类型转换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%90%E5%BC%8F%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%BD%AC%E6%8D%A2"><span class="toc-number">19.3.</span> <span class="toc-text">隐式字符编码转换</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#19-%E8%AE%B2%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E5%8F%AA%E6%9F%A5%E4%B8%80%E8%A1%8C%E7%9A%84%E8%AF%AD%E5%8F%A5%EF%BC%8C%E4%B9%9F%E6%89%A7%E8%A1%8C%E8%BF%99%E4%B9%88%E6%85%A2"><span class="toc-number">20.</span> <span class="toc-text">19 讲为什么我只查一行的语句，也执行这么慢</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BD%B1%E5%93%8D%E6%9F%A5%E8%AF%A2%E9%80%9F%E5%BA%A6%E7%9A%84%E5%87%A0%E7%A7%8D%E6%83%85%E5%86%B5"><span class="toc-number">20.1.</span> <span class="toc-text">影响查询速度的几种情况</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%B1%BB%EF%BC%9A%E6%9F%A5%E8%AF%A2%E9%95%BF%E6%97%B6%E9%97%B4%E4%B8%8D%E8%BF%94%E5%9B%9E"><span class="toc-number">20.1.1.</span> <span class="toc-text">第一类：查询长时间不返回</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AD%89MDL%E9%94%81"><span class="toc-number">20.1.1.1.</span> <span class="toc-text">等MDL锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AD%89flush"><span class="toc-number">20.1.1.2.</span> <span class="toc-text">等flush</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AD%89%E8%A1%8C%E9%94%81"><span class="toc-number">20.1.1.3.</span> <span class="toc-text">等行锁</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%B1%BB%EF%BC%9A%E6%9F%A5%E8%AF%A2%E6%85%A2"><span class="toc-number">20.1.2.</span> <span class="toc-text">第二类：查询慢</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%A8%E8%A1%A8%E6%89%AB%E6%8F%8F"><span class="toc-number">20.1.2.1.</span> <span class="toc-text">全表扫描</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#undo%E9%93%BE%E5%A4%AA%E9%95%BF"><span class="toc-number">20.1.2.2.</span> <span class="toc-text">undo链太长</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#20-%E8%AE%B2%E5%B9%BB%E8%AF%BB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%8C%E5%B9%BB%E8%AF%BB%E6%9C%89%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98"><span class="toc-number">21.</span> <span class="toc-text">20 讲幻读是什么，幻读有什么问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9D%9E%E7%B4%A2%E5%BC%95%E5%AD%97%E6%AE%B5%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E7%9A%84%E5%8A%A0%E9%94%81%E6%83%85%E5%86%B5"><span class="toc-number">21.1.</span> <span class="toc-text">非索引字段更新语句的加锁情况</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B9%BB%E8%AF%BB"><span class="toc-number">21.2.</span> <span class="toc-text">幻读</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%B9%BB%E8%AF%BB%EF%BC%9F"><span class="toc-number">21.3.</span> <span class="toc-text">如何解决幻读？</span></a></li></ol></li></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/blog/Redis/" title="Redis安装和常见数据类型命令"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/07.webp" onerror='this.onerror=null,this.src="/img/404.webp"' alt="Redis安装和常见数据类型命令"></a><div class="content"><a class="title" href="/blog/Redis/" title="Redis安装和常见数据类型命令">Redis安装和常见数据类型命令</a><time datetime="2023-10-01T06:51:00.000Z" title="发表于 2023-10-01 14:51:00">2023-10-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/" title="MySQL(6)实战45讲笔记"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/02.webp" onerror='this.onerror=null,this.src="/img/404.webp"' alt="MySQL(6)实战45讲笔记"></a><div class="content"><a class="title" href="/blog/MySQL(6)%E5%AE%9E%E6%88%9845%E8%AE%B2%E7%AC%94%E8%AE%B0/" title="MySQL(6)实战45讲笔记">MySQL(6)实战45讲笔记</a><time datetime="2023-10-01T06:50:06.000Z" title="发表于 2023-10-01 14:50:06">2023-10-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/MySQL(5)%E6%97%A5%E5%BF%97%E4%B8%8E%E5%A4%87%E4%BB%BD%E7%AF%87/" title="MySQL(5)日志与备份篇"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/07.webp" onerror='this.onerror=null,this.src="/img/404.webp"' alt="MySQL(5)日志与备份篇"></a><div class="content"><a class="title" href="/blog/MySQL(5)%E6%97%A5%E5%BF%97%E4%B8%8E%E5%A4%87%E4%BB%BD%E7%AF%87/" title="MySQL(5)日志与备份篇">MySQL(5)日志与备份篇</a><time datetime="2023-10-01T06:50:05.000Z" title="发表于 2023-10-01 14:50:05">2023-10-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/MySQL(4)%E4%BA%8B%E5%8A%A1%E7%AF%87/" title="MySQL(4)事务篇"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/01.webp" onerror='this.onerror=null,this.src="/img/404.webp"' alt="MySQL(4)事务篇"></a><div class="content"><a class="title" href="/blog/MySQL(4)%E4%BA%8B%E5%8A%A1%E7%AF%87/" title="MySQL(4)事务篇">MySQL(4)事务篇</a><time datetime="2023-10-01T06:50:04.000Z" title="发表于 2023-10-01 14:50:04">2023-10-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/blog/MySQL(3)%E7%B4%A2%E5%BC%95%E5%92%8C%E8%B0%83%E4%BC%98%E7%AF%87/" title="MySQL(3)索引和调优篇"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/cover_default_img/07.webp" onerror='this.onerror=null,this.src="/img/404.webp"' alt="MySQL(3)索引和调优篇"></a><div class="content"><a class="title" href="/blog/MySQL(3)%E7%B4%A2%E5%BC%95%E5%92%8C%E8%B0%83%E4%BC%98%E7%AF%87/" title="MySQL(3)索引和调优篇">MySQL(3)索引和调优篇</a><time datetime="2023-10-01T06:50:03.000Z" title="发表于 2023-10-01 14:50:03">2023-10-01</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url(/img/cover_default_img/02.webp)"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By spongehah</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">I wish you to become your own sun, no need to rely on who's light.<p><a target="_blank" href="https://hexo.io/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo" title="博客框架为Hexo"></a>&nbsp;<a target="_blank" href="https://butterfly.js.org/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender" title="主题采用butterfly"></a>&nbsp;<a target="_blank" href="https://www.jsdelivr.com/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr" title="本站使用JsDelivr为静态资源提供CDN加速"></a>&nbsp;<a target="_blank" href="https://github.com/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub" title="本站项目由Gtihub托管"></a>&nbsp; <a target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div class="js-pjax" id="rightMenu"><div class="rightMenu-group rightMenu-small"><a class="rightMenu-item" href="javascript:window.history.back();"><i class="fa fa-arrow-left"></i></a><a class="rightMenu-item" href="javascript:window.history.forward();"><i class="fa fa-arrow-right"></i></a><a class="rightMenu-item" href="javascript:window.location.reload();"><i class="fa fa-refresh"></i></a><a class="rightMenu-item" href="javascript:rmf.scrollToTop();"><i class="fa fa-arrow-up"></i></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-text"><a class="rightMenu-item" href="javascript:rmf.copySelect();"><i class="fa fa-copy"></i><span>复制</span></a><a class="rightMenu-item" href="javascript:window.open(&quot;https://www.baidu.com/s?wd=&quot;+window.getSelection().toString());window.location.reload();"><i class="iconfont icon-baidu"></i><span>百度搜索</span></a><a class="rightMenu-item" href="#post-comment" onclick="rmf.yinyong()"><i class="fa-solid fa-message"></i><span>引用文本评论</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-too"><a class="rightMenu-item" href="javascript:window.open(window.getSelection().toString());window.location.reload();"><i class="fa fa-link"></i><span>转到链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-paste"><a class="rightMenu-item" href="javascript:rmf.paste()"><i class="fa fa-copy"></i><span>粘贴</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-post"><a class="rightMenu-item" href="#post-comment"><i class="fas fa-comment"></i><span>空降评论</span></a><a class="rightMenu-item" href="javascript:rmf.copyWordsLink()"><i class="fa fa-link"></i><span>复制本文地址</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-to"><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>新窗口打开</span></a><a class="rightMenu-item" id="menu-too" href="javascript:rmf.open()"><i class="fa fa-link"></i><span>转到链接</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制链接</span></a></div><div class="rightMenu-group rightMenu-line hide" id="menu-img"><a class="rightMenu-item" href="javascript:rmf.saveAs()"><i class="fa fa-download"></i><span>保存图片</span></a><a class="rightMenu-item" href="javascript:rmf.openWithNewTab()"><i class="fa fa-window-restore"></i><span>在新窗口打开</span></a><a class="rightMenu-item" href="javascript:rmf.click()"><i class="fa fa-arrows-alt"></i><span>全屏显示</span></a><a class="rightMenu-item" href="javascript:rmf.copyLink()"><i class="fa fa-copy"></i><span>复制图片链接</span></a></div><div class="rightMenu-group rightMenu-line"><a class="rightMenu-item menu-link" href="/archives/"><i class="fa-solid fa-archive"></i><span>文章归档</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="fa-solid fa-folder-open"></i><span>文章分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="fa-solid fa-tags"></i><span>文章标签</span></a><a class="rightMenu-item" href="javascript:rmf.switchDarkMode();"><i class="fa fa-moon"></i><span>昼夜切换</span></a><a class="rightMenu-item" href="javascript:rmf.translate();"><i class="iconfont icon-fanti"></i><span>繁简转换</span></a><a class="rightMenu-item" href="javascript:rmf.switchReadMode();"><i class="fa fa-book"></i><span>阅读模式</span></a></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="/pluginsSrc/@fancyapps/ui/dist/fancybox/fancybox.umd.js"></script><script src="/pluginsSrc/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/pluginsSrc/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('/pluginsSrc/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.hahhome.top/',
      region: '',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))
  }

  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.hahhome.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      countELement.textContent = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('/pluginsSrc/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '7ecf16f704fd5834a3a5',
      clientSecret: 'ed4a99d0eb3e4480a27445dd2b6a03b96fa99ddf',
      repo: 'hahhome.github.io',
      owner: 'spongehah',
      admin: ['spongehah'],
      id: '8cea0b2fcd695eb1cf6fe84d189aa039',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    getCSS('/pluginsSrc/gitalk/dist/gitalk.css')
    getScript('/pluginsSrc/gitalk/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.textContent= n
  }
}

if ('Twikoo' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script defer src="https://npm.elemecdn.com/jquery@latest/dist/jquery.min.js"></script><script type="text/javascript" src="https://npm.elemecdn.com/jquery@latest/dist/jquery.min.js"></script><script async src="https://npm.elemecdn.com/tzy-blog/lib/js/theme/cursor.js"></script><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script defer data-pjax src="/js/cat.js"></script><script defer data-pjax src="/js/rightMenu.js"></script><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="/pluginsSrc/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="/pluginsSrc/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!0,POWERMODE.mobile=!1,document.body.addEventListener("input",POWERMODE)</script><script id="click-heart" src="/pluginsSrc/butterfly-extsrc/dist/click-heart.min.js" async mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script data-pjax>function butterfly_clock_anzhiyu_injector_config(){var e=document.getElementsByClassName("sticky_layout")[0];console.log("已挂载butterfly_clock_anzhiyu"),e&&e.insertAdjacentHTML("afterbegin",'<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>')}for(var elist="null".split(","),cpage=location.pathname,epage="all",qweather_key="b16a1fa0e63c46a4b8f28abfb06ae3fe",gaud_map_key="e2b04289e870b005374ee030148d64fd&s=rsv3",baidu_ak_key="undefined",flag=0,clock_rectangle="112.982279,28.19409",clock_default_rectangle_enable="false",i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_clock_anzhiyu_injector_config()</script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"left","width":150,"height":300,"hOffset":20,"vOffset":-20},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/"});</script></body></html>